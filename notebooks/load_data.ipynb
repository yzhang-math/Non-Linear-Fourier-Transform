{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5365a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script to load and inspect pickle files from the phylogenetic GFlowNet repository.\n",
    "This script can handle both sequence data and other pickle files in the repository.\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from typing import Any, Dict, List, Union\n",
    "import numpy as np\n",
    "\n",
    "def load_pickle_file(filepath: str) -> Any:\n",
    "    \"\"\"\n",
    "    Load a pickle file and return its contents.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the pickle file\n",
    "        \n",
    "    Returns:\n",
    "        Any: Contents of the pickle file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3222df54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alligator_mississippiensis', 'Ambystoma_mexicanum', 'Amphiuma_tridactylum', 'Bufo_valliceps', 'Discoglossus_pictus', 'Eleutherodactylus_cuneatus', 'Gallus_gallus', 'Gastrophryne_carolinensis', 'Grandisonia_alternans', 'Heterodon_platyrhinos', 'Homo_sapiens', 'Hyla_cinerea', 'Hypogeophis_rostratus', 'Ichthyophis_bannanicus', 'Latimeria_chalumnae', 'Mus_musculus', 'Nesomantis_thomasseti', 'Oryctolagus_cuniculus', 'Plethodon_yonhalossee', 'Rattus_norvegicus', 'Scaphiopus_holbrooki', 'Sceloporus_undulatus', 'Siren_intermedia', 'Trachemys_scripta', 'Turdus_migratorius', 'Typhlonectes_natans', 'Xenopus_laevis']\n"
     ]
    }
   ],
   "source": [
    "from transformers.models.bert.configuration_bert import BertConfig\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from typing import Any, Dict, List, Union\n",
    "import numpy as np\n",
    "\n",
    "path = 'dataset/benchmark_datasets/DS1.pickle'\n",
    "dnadata = load_pickle_file(path)\n",
    "#print(data)\n",
    "dnakeys = list(dnadata.keys())\n",
    "print(dnakeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f88fd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 791, 768])\n",
      "tensor([[[ 0.0868,  0.1897,  0.3563,  ...,  0.5004,  0.5196,  0.0335],\n",
      "         [ 0.0525,  0.0992,  0.0924,  ...,  0.4640,  0.3608, -0.1479],\n",
      "         [-0.1916,  0.0549,  0.0168,  ...,  0.2166,  0.2230, -0.0431],\n",
      "         ...,\n",
      "         [ 0.2057, -0.1602,  0.1408,  ...,  0.2269,  0.2780, -0.3086],\n",
      "         [ 0.1618, -0.1540,  0.1913,  ...,  0.1918,  0.2205, -0.2679],\n",
      "         [-0.0283,  0.2904,  0.4328,  ...,  0.1829,  0.0898, -0.1776]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/.cache/huggingface/modules/transformers_modules/zhihan1996/DNABERT-2-117M/7bce263b15377fc15361f52cfab88f8b586abda0/bert_layers.py:433: UserWarning: Increasing alibi size from 512 to 791\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, BertConfig\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load model and move to GPU\n",
    "config = BertConfig.from_pretrained(\"zhihan1996/DNABERT-2-117M\")\n",
    "model = AutoModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True, config=config)\n",
    "model = model.to(device)  # Move model to GPU\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
    "\n",
    "# Process your DNA sequence\n",
    "dna = \"ACGTAGCATCGGATCTATCTATCGACACTTGGTTATCGATCTACGAGCATCTCGTTAGC\"\n",
    "dna = dnadata[dnakeys[0]]\n",
    "inputs = tokenizer(dna, return_tensors='pt')[\"input_ids\"]\n",
    "inputs = inputs.to(device)  # Move inputs to GPU\n",
    "\n",
    "# Forward pass\n",
    "hidden_states = model(inputs)[0]\n",
    "print(hidden_states.shape)\n",
    "print(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7fbb773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "Number of GPUs: 2\n",
      "Current GPU: NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "Basic CUDA operations work!\n",
      "PyTorch import and basic operations successful!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Test basic CUDA operations\n",
    "    x = torch.randn(3, 3).cuda()\n",
    "    y = torch.randn(3, 3).cuda()\n",
    "    z = torch.mm(x, y)\n",
    "    print(\"Basic CUDA operations work!\")\n",
    "    \n",
    "print(\"PyTorch import and basic operations successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55a21375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating Tree ---\n",
      "\n",
      "            /-0, 0.1\n",
      "      /5, 0.2\n",
      "     |      \\-1, 0.1\n",
      "-4, 0.0\n",
      "     |      /-2, 0.1\n",
      "      \\6, 0.2\n",
      "            \\-3, 0.1\n",
      "-------------------------\n",
      "âœ… Calculated Log-Likelihood: -27.0373\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from ete3 import TreeNode\n",
    "from torch import nn\n",
    "\n",
    "# --- Helper Classes and Functions (Adapted from provided code & standard models) ---\n",
    "\n",
    "class MockCfgNode:\n",
    "    \"\"\"A mock configuration class to replace OmegaConf/easydict objects.\"\"\"\n",
    "    def __init__(self, d=None):\n",
    "        if d is None:\n",
    "            d = {}\n",
    "        for k, v in d.items():\n",
    "            setattr(self, k, MockCfgNode(v) if isinstance(v, dict) else v)\n",
    "\n",
    "CHARACTERS_MAPS = {\n",
    "    'DNA': {\n",
    "        'A': [1., 0., 0., 0.], 'C': [0., 1., 0., 0.],\n",
    "        'G': [0., 0., 1., 0.], 'T': [0., 0., 0., 1.],\n",
    "        'N': [1., 1., 1., 1.]\n",
    "    }\n",
    "}\n",
    "\n",
    "class PhyloTreeReward:\n",
    "    \"\"\"Mock reward function class, not used in calculation but required for environment setup.\"\"\"\n",
    "    def __init__(self, reward_cfg):\n",
    "        self.C = reward_cfg.C\n",
    "        self.scale = reward_cfg.SCALE\n",
    "    def __call__(self, log_score):\n",
    "        return (self.C + log_score) / self.scale\n",
    "\n",
    "class MockEdgeEnv:\n",
    "    \"\"\"Mock edge environment, as noise perturbation is not needed for likelihood calculation.\"\"\"\n",
    "    def generate_random_perturbation(self, edge_length, is_root):\n",
    "        return 0.0\n",
    "\n",
    "def build_edge_env(cfg):\n",
    "    \"\"\"Factory function for the mock edge environment.\"\"\"\n",
    "    return MockEdgeEnv()\n",
    "\n",
    "class EvolutionModelTorch(nn.Module):\n",
    "    \"\"\"\n",
    "    A PyTorch implementation of a DNA evolution model required by the environment.\n",
    "    This example uses the Jukes-Cantor (JC69) model.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='JC69'):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        # Rate matrix Q for JC69 model\n",
    "        self.Q = torch.tensor([\n",
    "            [-3, 1, 1, 1], [1, -3, 1, 1],\n",
    "            [1, 1, -3, 1], [1, 1, 1, -3]\n",
    "        ], dtype=torch.float32) / 4.0\n",
    "        # Equilibrium frequencies pi for JC69 (uniform)\n",
    "        self.pi = torch.tensor([0.25, 0.25, 0.25, 0.25], dtype=torch.float32)\n",
    "\n",
    "    def get_transition_matrix(self, t):\n",
    "        \"\"\"Calculates the transition probability matrix P(t) = expm(Qt).\"\"\"\n",
    "        return torch.matrix_exp(self.Q * t.item())\n",
    "\n",
    "    def compute_partial_prob(self, data, at_root):\n",
    "        \"\"\"\n",
    "        Implements Felsenstein's pruning algorithm to compute partial likelihoods at an internal node.\n",
    "        \n",
    "        Args:\n",
    "            data (list): A list like [[child1_likelihoods, branch1_length], [child2_likelihoods, branch2_length]].\n",
    "            at_root (bool): Flag indicating if the current node is the root of the tree.\n",
    "        \"\"\"\n",
    "        child_probs = []\n",
    "        for partial_likelihoods, branch_length in data:\n",
    "            P = self.get_transition_matrix(branch_length)\n",
    "            # Transformed likelihoods from child node: L_child @ P.T\n",
    "            prob = torch.matmul(partial_likelihoods.squeeze(0), P.T)\n",
    "            child_probs.append(prob)\n",
    "\n",
    "        # Merge likelihoods from children by element-wise multiplication\n",
    "        merged_likelihoods = child_probs[0]\n",
    "        for i in range(1, len(child_probs)):\n",
    "            merged_likelihoods *= child_probs[i]\n",
    "        \n",
    "        merged_likelihoods = merged_likelihoods.unsqueeze(0)\n",
    "\n",
    "        if at_root:\n",
    "            # For the root, calculate the final site likelihoods weighted by equilibrium frequencies\n",
    "            likelihood_per_site = torch.sum(self.pi * merged_likelihoods.squeeze(0), dim=1)\n",
    "            # Total log-likelihood is the sum of the log of site likelihoods\n",
    "            log_score = torch.sum(torch.log(likelihood_per_site))\n",
    "            return merged_likelihoods, log_score\n",
    "        \n",
    "        return merged_likelihoods, None\n",
    "\n",
    "class PhylogenticTreeEnv(nn.Module):\n",
    "    \"\"\"\n",
    "    The environment for phylogenetic tree operations, adapted from the provided source.\n",
    "    This version is simplified to focus solely on the `compute_tree_log_score` method.\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg, sequences):\n",
    "        super(PhylogenticTreeEnv, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.sequences = sequences\n",
    "        self.reward_fn = PhyloTreeReward(cfg.ENV.REWARD)\n",
    "        self.chars_dict = CHARACTERS_MAPS[cfg.ENV.SEQUENCE_TYPE]\n",
    "        seq_arrays = np.array([self.seq2array(seq) for seq in self.sequences])\n",
    "        self.seq_arrays = torch.nn.Parameter(torch.tensor(seq_arrays, dtype=torch.float32), requires_grad=False)\n",
    "        self.evolution_model = EvolutionModelTorch(cfg.ENV.EVOLUTION_MODEL)\n",
    "        self.edge_env = build_edge_env(cfg)\n",
    "\n",
    "    def seq2array(self, seq):\n",
    "        \"\"\"Converts a sequence string to a numpy array based on character maps.\"\"\"\n",
    "        return np.array([self.chars_dict[char] for char in seq])\n",
    "\n",
    "    def compute_tree_log_score(self, ete_tree, with_noise):\n",
    "        \"\"\"\n",
    "        Computes the log-likelihood of a given ete_tree object.\n",
    "\n",
    "        Args:\n",
    "            ete_tree (ete3.TreeNode): The tree to evaluate.\n",
    "            with_noise (bool): If True, applies GFN-specific perturbations. Should be False for pure likelihood.\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing the final log-likelihood tensor, the dictionary of feature vectors, \n",
    "            and the discrete factor (0 if with_noise is False).\n",
    "        \"\"\"\n",
    "        feature_dict = {}\n",
    "        final_log_score = None\n",
    "\n",
    "        # Traverse the tree from leaves up to the root (postorder)\n",
    "        for node in ete_tree.traverse(\"postorder\"):\n",
    "            node_id = int(node.name)\n",
    "            if node.is_leaf():\n",
    "                # For leaves, the feature is the one-hot encoded sequence data\n",
    "                feature_dict[node_id] = self.seq_arrays[node_id].unsqueeze(0)\n",
    "            else:\n",
    "                # For internal nodes, gather data from children\n",
    "                child_data = []\n",
    "                for child in node.children:\n",
    "                    child_id = int(child.name)\n",
    "                    # Data includes child's partial likelihoods and its connecting branch length\n",
    "                    child_data.append(\n",
    "                        [feature_dict[child_id], torch.tensor([child.dist])]\n",
    "                    )\n",
    "                \n",
    "                # Compute the partial likelihood for the current node\n",
    "                feature, log_score = self.evolution_model.compute_partial_prob(child_data, node.is_root())\n",
    "                feature_dict[node_id] = feature\n",
    "                if node.is_root():\n",
    "                    final_log_score = log_score\n",
    "        \n",
    "        return final_log_score, feature_dict, 0.0\n",
    "\n",
    "# --- Main Evaluation Function ---\n",
    "\n",
    "def evaluate_tree_log_probability(env, newick_tree_string):\n",
    "    \"\"\"\n",
    "    High-level function to evaluate the log-likelihood of a phylogenetic tree.\n",
    "\n",
    "    Args:\n",
    "        env: object of PhylogenticTreeEnv that contains sequences and model\n",
    "        newick_tree_string (str): The tree in Newick format. Leaf names must be\n",
    "                                  string integers matching sequence indices.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # 3. Parse the Newick string into an ete3 tree object\n",
    "    ete_tree = TreeNode(newick_tree_string)\n",
    "    \n",
    "    # 4. Name internal nodes, which is required for the feature dictionary keys\n",
    "    internal_node_counter = num_sequences\n",
    "    for node in ete_tree.traverse(\"preorder\"):\n",
    "        if not node.is_leaf() and not node.name:\n",
    "            node.name = str(internal_node_counter)\n",
    "            internal_node_counter += 1\n",
    "\n",
    "    print(\"--- Evaluating Tree ---\")\n",
    "    print(ete_tree.get_ascii(attributes=[\"name\", \"dist\"]))\n",
    "    print(\"-\" * 25)\n",
    "\n",
    "    # 5. Compute the log score (log-likelihood)\n",
    "    # Set with_noise=False to get the pure likelihood without GFN-related perturbations.\n",
    "    log_score_tensor, _, _ = env.compute_tree_log_score(ete_tree, with_noise=False)\n",
    "    log_likelihood = log_score_tensor.item()\n",
    "\n",
    "    print(f\"âœ… Calculated Log-Likelihood: {log_likelihood:.4f}\")\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Example Usage ---\n",
    "\n",
    "    # 1. Define the aligned DNA sequences\n",
    "    dna_sequences = [\n",
    "        \"AGAACT\",  # Corresponds to leaf \"0\"\n",
    "        \"AGATGT\",  # Corresponds to leaf \"1\"\n",
    "        \"CGAACT\",  # Corresponds to leaf \"2\"\n",
    "        \"CGATGT\",  # Corresponds to leaf \"3\"\n",
    "    ]\n",
    "\n",
    "    # 2. Define the tree in Newick format with branch lengths.\n",
    "    # Note: Leaf names must match the indices of the sequences list.\n",
    "    newick_tree = \"((0:0.1, 1:0.1):0.2, (2:0.1, 3:0.1):0.2);\"\n",
    "\n",
    "    # 3. Evaluate the log-likelihood of the tree\n",
    "\n",
    "    sequences = dna_sequences\n",
    "\n",
    "    num_sequences = len(sequences)\n",
    "    if not sequences:\n",
    "        raise ValueError(\"Sequence list cannot be empty.\")\n",
    "    seq_len = len(sequences[0])\n",
    "\n",
    "    # 3.1. Configure parameters for the environment\n",
    "    cfg = MockCfgNode({\n",
    "        'ENV': {\n",
    "            'REWARD': {'C': 0, 'SCALE': 1.0},\n",
    "            'SEQUENCE_TYPE': 'DNA',\n",
    "            'EVOLUTION_MODEL': 'JC69'\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # 3.2. Initialize the phylogenetic environment\n",
    "    env = PhylogenticTreeEnv(cfg, sequences)\n",
    "\n",
    "    # 3.3. Evaluate the tree log-likelihood\n",
    "    evaluate_tree_log_probability(\n",
    "        env=env,\n",
    "        newick_tree_string=newick_tree\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e5624ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Part 1: Generating DNA Sequence Embeddings ---\n",
      "  Processing sequence 1/4...\n",
      "  Processing sequence 2/4...\n",
      "  Processing sequence 3/4...\n",
      "  Processing sequence 4/4...\n",
      "âœ… Embeddings generated.\n",
      "\n",
      "--- Part 2: Generating Tree Vector Embedding ---\n",
      "âœ… Tree vector embedding generated.\n",
      "   Shape: torch.Size([1, 64])\n",
      "   Vector: [[-0.09252521 -0.12469912 -0.11347823 -0.00265401  0.06644897  0.10902996\n",
      "   0.01276676  0.06076688  0.06366131 -0.03113133 -0.06613523  0.07356571\n",
      "   0.06505363  0.00751065  0.02706065  0.06118593 -0.08459453 -0.05586729\n",
      "   0.12872213 -0.02909402 -0.071957   -0.00684902  0.0548784  -0.07346763\n",
      "  -0.09493774 -0.06481383 -0.08488901  0.05296412  0.0423707   0.08750881\n",
      "  -0.02373612  0.06513753 -0.01547156 -0.07664096 -0.01115914  0.11003086\n",
      "  -0.08134507 -0.05298244 -0.08254381 -0.04761319 -0.0085787  -0.02501148\n",
      "   0.11579509 -0.03822134  0.08364971 -0.06851368 -0.07431819 -0.11657837\n",
      "  -0.01664385 -0.04384599 -0.05821709  0.05566616  0.03106859  0.06425551\n",
      "   0.04265103  0.06272723  0.07730101  0.00524957  0.09708128 -0.03081987\n",
      "  -0.04008798 -0.02362586  0.08495826  0.05588727]]\n",
      "\n",
      "--- Part 3: Calculating Likelihood as Reward Signal ---\n",
      "âœ… Calculated Log-Likelihood (Reward): -27.0373\n",
      "\n",
      "--- Pipeline Complete ---\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ete3 import TreeNode\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# PyTorch Geometric for the Tree GNN\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# --- PART 1: DNA Sequence Embedding (Adapted from your notebook) ---\n",
    "\n",
    "def get_dna_embeddings(sequences, model, tokenizer, device):\n",
    "    \"\"\"\n",
    "    Generates embeddings for a list of DNA sequences using DNABERT.\n",
    "\n",
    "    Args:\n",
    "        sequences (list[str]): A list of DNA sequences.\n",
    "        model: The pre-trained DNABERT model.\n",
    "        tokenizer: The DNABERT tokenizer.\n",
    "        device: The torch device (e.g., 'cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of shape [num_sequences, embedding_dim]\n",
    "    \"\"\"\n",
    "    print(\"--- Part 1: Generating DNA Sequence Embeddings ---\")\n",
    "    all_embeddings = []\n",
    "    for i, seq in enumerate(sequences):\n",
    "        print(f\"  Processing sequence {i+1}/{len(sequences)}...\")\n",
    "        inputs = tokenizer(seq, return_tensors='pt')[\"input_ids\"].to(device)\n",
    "        with torch.no_grad():\n",
    "            hidden_states = model(inputs)[0] # [1, sequence_length, 768]\n",
    "        \n",
    "        # Use mean pooling to get a fixed-size embedding for the sequence\n",
    "        sequence_embedding = hidden_states.mean(dim=1)\n",
    "        all_embeddings.append(sequence_embedding)\n",
    "    \n",
    "    print(\"âœ… Embeddings generated.\\n\")\n",
    "    return torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "# --- PART 2: Tree Embedding with a Graph Neural Network ---\n",
    "\n",
    "class TreeGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A Graph Neural Network to generate an embedding for a phylogenetic tree.\n",
    "    It takes node features (from DNABERT) and the tree structure as input.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim=128, output_dim=64):\n",
    "        super(TreeGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Forward pass for the GNN.\n",
    "\n",
    "        Args:\n",
    "            data (torch_geometric.data.Data): A graph data object with attributes:\n",
    "                - x: Node feature matrix [num_nodes, input_dim]\n",
    "                - edge_index: Graph connectivity [2, num_edges]\n",
    "                - batch: Batch vector [num_nodes] for pooling\n",
    "        \"\"\"\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # GCN layers\n",
    "        x = self.relu(self.conv1(x, edge_index))\n",
    "        x = self.relu(self.conv2(x, edge_index))\n",
    "\n",
    "        # Global pooling to get a single vector for the entire graph (tree)\n",
    "        graph_embedding = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Final linear layer\n",
    "        tree_vector = self.output_layer(graph_embedding)\n",
    "        return tree_vector\n",
    "\n",
    "def newick_to_graph_data(newick_string, leaf_embeddings):\n",
    "    \"\"\"\n",
    "    Converts a Newick tree string and leaf embeddings into a PyG Data object.\n",
    "\n",
    "    Args:\n",
    "        newick_string (str): The tree in Newick format.\n",
    "        leaf_embeddings (torch.Tensor): A tensor of embeddings for the leaf nodes.\n",
    "\n",
    "    Returns:\n",
    "        torch_geometric.data.Data: The graph representation for the GNN.\n",
    "    \"\"\"\n",
    "    ete_tree = TreeNode(newick_string)\n",
    "    \n",
    "    # Map nodes to integer indices\n",
    "    node_map = {node: i for i, node in enumerate(ete_tree.traverse(\"preorder\"))}\n",
    "    num_nodes = len(node_map)\n",
    "    \n",
    "    # Create the node feature matrix 'x'\n",
    "    embedding_dim = leaf_embeddings.shape[1]\n",
    "    x = torch.zeros((num_nodes, embedding_dim), dtype=torch.float32)\n",
    "\n",
    "    # Build the edge index (adjacency list)\n",
    "    edge_list = []\n",
    "    for node in ete_tree.traverse():\n",
    "        if not node.is_root():\n",
    "            parent_idx = node_map[node.up]\n",
    "            child_idx = node_map[node]\n",
    "            edge_list.append([parent_idx, child_idx])\n",
    "            edge_list.append([child_idx, parent_idx]) # Add edges in both directions\n",
    "\n",
    "        # Assign pre-computed embeddings to leaf nodes\n",
    "        if node.is_leaf():\n",
    "            leaf_idx = int(node.name)\n",
    "            x[node_map[node]] = leaf_embeddings[leaf_idx]\n",
    "\n",
    "    edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "\n",
    "# --- PART 3: Likelihood Evaluation as Reward (Adapted from your notebook) ---\n",
    "# NOTE: This section is a direct copy of the necessary classes and functions\n",
    "# from your `evaluate_tree_log_probability` code for self-containment.\n",
    "\n",
    "class MockCfgNode:\n",
    "    def __init__(self, d=None):\n",
    "        if d is None: d = {}\n",
    "        for k, v in d.items():\n",
    "            setattr(self, k, MockCfgNode(v) if isinstance(v, dict) else v)\n",
    "\n",
    "CHARACTERS_MAPS = {'DNA': {'A': [1.,0.,0.,0.], 'C': [0.,1.,0.,0.], 'G': [0.,0.,1.,0.], 'T': [0.,0.,0.,1.], 'N': [1.,1.,1.,1.]}}\n",
    "\n",
    "class PhyloTreeReward:\n",
    "    def __init__(self, reward_cfg):\n",
    "        self.C = reward_cfg.C\n",
    "        self.scale = reward_cfg.SCALE\n",
    "    def __call__(self, log_score):\n",
    "        return (self.C + log_score) / self.scale\n",
    "\n",
    "class EvolutionModelTorch(nn.Module):\n",
    "    def __init__(self, model_name='JC69'):\n",
    "        super().__init__()\n",
    "        self.Q = torch.tensor([[-3,1,1,1],[1,-3,1,1],[1,1,-3,1],[1,1,1,-3]], dtype=torch.float32) / 4.0\n",
    "        self.pi = torch.tensor([0.25, 0.25, 0.25, 0.25], dtype=torch.float32)\n",
    "    def get_transition_matrix(self, t):\n",
    "        return torch.matrix_exp(self.Q * t.item())\n",
    "    def compute_partial_prob(self, data, at_root):\n",
    "        child_probs = [torch.matmul(p.squeeze(0), self.get_transition_matrix(bl).T) for p, bl in data]\n",
    "        merged_likelihoods = child_probs[0]\n",
    "        for i in range(1, len(child_probs)): merged_likelihoods *= child_probs[i]\n",
    "        merged_likelihoods = merged_likelihoods.unsqueeze(0)\n",
    "        if at_root:\n",
    "            log_score = torch.sum(torch.log(torch.sum(self.pi * merged_likelihoods.squeeze(0), dim=1)))\n",
    "            return merged_likelihoods, log_score\n",
    "        return merged_likelihoods, None\n",
    "\n",
    "class PhylogenticTreeEnv(nn.Module):\n",
    "    def __init__(self, cfg, sequences):\n",
    "        super(PhylogenticTreeEnv, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.sequences = sequences\n",
    "        self.chars_dict = CHARACTERS_MAPS[cfg.ENV.SEQUENCE_TYPE]\n",
    "        seq_arrays = np.array([np.array([self.chars_dict[c] for c in s]) for s in self.sequences])\n",
    "        self.seq_arrays = torch.nn.Parameter(torch.tensor(seq_arrays, dtype=torch.float32), requires_grad=False)\n",
    "        self.evolution_model = EvolutionModelTorch(cfg.ENV.EVOLUTION_MODEL)\n",
    "    def compute_tree_log_score(self, ete_tree):\n",
    "        feature_dict = {}\n",
    "        final_log_score = None\n",
    "        for node in ete_tree.traverse(\"postorder\"):\n",
    "            node_id = int(node.name)\n",
    "            if node.is_leaf():\n",
    "                feature_dict[node_id] = self.seq_arrays[node_id].unsqueeze(0)\n",
    "            else:\n",
    "                child_data = [[feature_dict[int(c.name)], torch.tensor([c.dist])] for c in node.children]\n",
    "                feature, log_score = self.evolution_model.compute_partial_prob(child_data, node.is_root())\n",
    "                feature_dict[node_id] = feature\n",
    "                if node.is_root():\n",
    "                    final_log_score = log_score\n",
    "        return final_log_score\n",
    "\n",
    "def get_tree_likelihood_reward(sequences, newick_tree_string):\n",
    "    \"\"\"\n",
    "    Calculates the log-likelihood of a tree, which serves as the reward.\n",
    "    \"\"\"\n",
    "    print(\"--- Part 3: Calculating Likelihood as Reward Signal ---\")\n",
    "    cfg = MockCfgNode({'ENV': {'REWARD': {'C': 0, 'SCALE': 1.0}, 'SEQUENCE_TYPE': 'DNA', 'EVOLUTION_MODEL': 'JC69'}})\n",
    "    env = PhylogenticTreeEnv(cfg, sequences)\n",
    "    \n",
    "    ete_tree = TreeNode(newick_tree_string)\n",
    "    internal_node_counter = len(sequences)\n",
    "    for node in ete_tree.traverse(\"preorder\"):\n",
    "        if not node.is_leaf() and not node.name:\n",
    "            node.name = str(internal_node_counter)\n",
    "            internal_node_counter += 1\n",
    "    \n",
    "    log_score_tensor = env.compute_tree_log_score(ete_tree)\n",
    "    reward = log_score_tensor.item()\n",
    "    print(f\"âœ… Calculated Log-Likelihood (Reward): {reward:.4f}\\n\")\n",
    "    return reward\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Setup ---\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\\n\")\n",
    "    \n",
    "    # Use the example sequences and tree from your likelihood script\n",
    "    dna_sequences = [\"AGAACT\", \"AGATGT\", \"CGAACT\", \"CGATGT\"]\n",
    "    newick_tree = \"((0:0.1, 1:0.1):0.2, (2:0.1, 3:0.1):0.2);\"\n",
    "    \n",
    "    # --- Part 1: Generate Sequence Embeddings ---\n",
    "    dnabert_model = AutoModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True).to(device)\n",
    "    dnabert_tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
    "    \n",
    "    leaf_node_embeddings = get_dna_embeddings(dna_sequences, dnabert_model, dnabert_tokenizer, device)\n",
    "\n",
    "    # --- Part 2: Generate Tree Embedding ---\n",
    "    print(\"--- Part 2: Generating Tree Vector Embedding ---\")\n",
    "    # Convert tree to graph format for the GNN\n",
    "    graph_data = newick_to_graph_data(newick_tree, leaf_node_embeddings.to('cpu'))\n",
    "    graph_data = graph_data.to(device) # Move graph data to the selected device\n",
    "    graph_data.batch = torch.zeros(graph_data.num_nodes, dtype=torch.long).to(device) # Add batch vector\n",
    "\n",
    "    # Initialize and run the TreeGNN model\n",
    "    tree_gnn_model = TreeGNN(input_dim=leaf_node_embeddings.shape[1]).to(device)\n",
    "    tree_vector_embedding = tree_gnn_model(graph_data)\n",
    "    \n",
    "    print(\"âœ… Tree vector embedding generated.\")\n",
    "    print(f\"   Shape: {tree_vector_embedding.shape}\")\n",
    "    print(f\"   Vector: {tree_vector_embedding.detach().cpu().numpy()}\\n\")\n",
    "\n",
    "    # --- Part 3: Get Reward Signal ---\n",
    "    reward = get_tree_likelihood_reward(dna_sequences, newick_tree)\n",
    "\n",
    "    print(\"--- Pipeline Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1881c734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training function is defined. Uncomment run_training() to execute.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from itertools import combinations\n",
    "import math\n",
    "\n",
    "# --- PART 1: REWARD CALCULATION (Adapted from your provided code) ---\n",
    "# This section remains the same, as it's our \"environment\"\n",
    "\n",
    "class MockCfgNode:\n",
    "    def __init__(self, d=None):\n",
    "        if d is None: d = {}\n",
    "        for k, v in d.items(): setattr(self, k, MockCfgNode(v) if isinstance(v, dict) else v)\n",
    "\n",
    "CHARACTERS_MAPS = {'DNA': {'A': [1.,0.,0.,0.], 'C': [0.,1.,0.,0.], 'G': [0.,0.,1.,0.], 'T': [0.,0.,0.,1.], 'N': [1.,1.,1.,1.]}}\n",
    "\n",
    "class EvolutionModelTorch(nn.Module):\n",
    "    def __init__(self, model_name='JC69'):\n",
    "        super().__init__()\n",
    "        self.Q = torch.tensor([[-3,1,1,1],[1,-3,1,1],[1,1,-3,1],[1,1,1,-3]], dtype=torch.float32) / 4.0\n",
    "        self.pi = torch.tensor([0.25, 0.25, 0.25, 0.25], dtype=torch.float32)\n",
    "    def get_transition_matrix(self, t):\n",
    "        return torch.matrix_exp(self.Q * t.item())\n",
    "    def compute_partial_prob(self, data, at_root):\n",
    "        child_probs = [torch.matmul(p.squeeze(0), self.get_transition_matrix(bl).T) for p, bl in data]\n",
    "        merged_likelihoods = child_probs[0]\n",
    "        for i in range(1, len(child_probs)): merged_likelihoods *= child_probs[i]\n",
    "        merged_likelihoods = merged_likelihoods.unsqueeze(0)\n",
    "        if at_root:\n",
    "            likelihood_per_site = torch.sum(self.pi * merged_likelihoods.squeeze(0), dim=1)\n",
    "            # Add a small epsilon to prevent log(0)\n",
    "            log_score = torch.sum(torch.log(likelihood_per_site + 1e-40))\n",
    "            return merged_likelihoods, log_score\n",
    "        return merged_likelihoods, None\n",
    "\n",
    "class PhylogenticTreeEnv(nn.Module):\n",
    "    def __init__(self, cfg, sequences, device):\n",
    "        super(PhylogenticTreeEnv, self).__init__()\n",
    "        self.device = device\n",
    "        self.evolution_model = EvolutionModelTorch().to(device)\n",
    "        self.chars_dict = CHARACTERS_MAPS[cfg.ENV.SEQUENCE_TYPE]\n",
    "        seq_arrays = np.array([np.array([self.chars_dict[c] for c in s]) for s in sequences])\n",
    "        self.seq_arrays = torch.nn.Parameter(torch.tensor(seq_arrays, dtype=torch.float32), requires_grad=False).to(device)\n",
    "    def compute_tree_log_score(self, ete_tree):\n",
    "        from ete3 import TreeNode # Import locally\n",
    "        feature_dict = {}\n",
    "        # Ensure all nodes have names\n",
    "        internal_node_counter = self.seq_arrays.shape[0]\n",
    "        for node in ete_tree.traverse(\"preorder\"):\n",
    "            if not node.is_leaf() and not node.name:\n",
    "                node.name = str(internal_node_counter)\n",
    "                internal_node_counter += 1\n",
    "        \n",
    "        for node in ete_tree.traverse(\"postorder\"):\n",
    "            node_id = int(node.name)\n",
    "            if node.is_leaf():\n",
    "                feature_dict[node_id] = self.seq_arrays[node_id].unsqueeze(0)\n",
    "            else:\n",
    "                child_data = [[feature_dict[int(c.name)], torch.tensor([c.dist], device=self.device)] for c in node.children]\n",
    "                feature, log_score = self.evolution_model.compute_partial_prob(child_data, node.is_root())\n",
    "                feature_dict[node_id] = feature\n",
    "                if node.is_root(): return log_score\n",
    "        return torch.tensor(float('-inf')) # Should not be reached\n",
    "\n",
    "def get_reward(newick_string, sequences, env):\n",
    "    from ete3 import TreeNode # Import locally\n",
    "    if not newick_string or not newick_string.endswith(';'): return -math.inf, \"Invalid Newick\"\n",
    "    try:\n",
    "        tree = TreeNode(newick_string)\n",
    "        # Check if the tree contains all leaves\n",
    "        leaf_names_in_tree = set(tree.get_leaf_names())\n",
    "        expected_leaf_names = set(str(i) for i in range(len(sequences)))\n",
    "        if leaf_names_in_tree != expected_leaf_names:\n",
    "            return -math.inf, \"Tree missing leaves\"\n",
    "        ll = env.compute_tree_log_score(tree)\n",
    "        return ll.item(), \"OK\"\n",
    "    except Exception as e:\n",
    "        return -math.inf, f\"Reward Error: {e}\"\n",
    "\n",
    "# --- PART 2: THE REINFORCEMENT LEARNING AGENT ---\n",
    "\n",
    "class TreeBuilder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim=128):\n",
    "        super(TreeBuilder, self).__init__()\n",
    "        # Network to score pairs for merging\n",
    "        self.pair_scorer = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        # Network to predict branch lengths\n",
    "        self.branch_predictor = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2), # Predicts 2 branch lengths (child1, child2)\n",
    "            nn.Sigmoid() # Scale branch lengths between 0 and 1\n",
    "        )\n",
    "        # Network to create the embedding for the new parent node\n",
    "        self.parent_embedding_creator = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, node_embeddings):\n",
    "        # Create all possible pairs of nodes\n",
    "        indices = list(combinations(range(len(node_embeddings)), 2))\n",
    "        emb1_indices, emb2_indices = zip(*indices)\n",
    "        \n",
    "        emb1 = node_embeddings[list(emb1_indices)]\n",
    "        emb2 = node_embeddings[list(emb2_indices)]\n",
    "        \n",
    "        # Concatenate pairs\n",
    "        concatenated_pairs = torch.cat((emb1, emb2), dim=1)\n",
    "        \n",
    "        # Get scores (logits) for each pair\n",
    "        pair_logits = self.pair_scorer(concatenated_pairs).squeeze(-1)\n",
    "        \n",
    "        return pair_logits, indices\n",
    "\n",
    "# --- PART 3: TRAINING & INFERENCE SCRIPT ---\n",
    "\n",
    "def get_dna_embeddings(sequences, model, tokenizer, device):\n",
    "    all_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for seq in sequences:\n",
    "            inputs = tokenizer(seq, return_tensors='pt')[\"input_ids\"].to(device)\n",
    "            hidden_states = model(inputs)[0]\n",
    "            all_embeddings.append(hidden_states.mean(dim=1))\n",
    "    return torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "def run_training():\n",
    "    # --- Setup ---\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    DNA_SEQUENCES = [\"AGAACT\", \"AGATGT\", \"CGAACT\", \"CGATGT\"]\n",
    "    n_leaves = len(DNA_SEQUENCES)\n",
    "    \n",
    "    # Hyperparameters\n",
    "    epochs = 5000\n",
    "    learning_rate = 1e-4\n",
    "    reward_baseline = -35.0 # Helps stabilize training. Start with a reasonable guess.\n",
    "\n",
    "    # --- Pre-compute embeddings ---\n",
    "    print(\"Pre-computing DNABERT embeddings...\")\n",
    "    dnabert_model = AutoModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True).to(device)\n",
    "    dnabert_model.eval()\n",
    "    dnabert_tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
    "    leaf_embeddings = get_dna_embeddings(DNA_SEQUENCES, dnabert_model, dnabert_tokenizer, device)\n",
    "    embedding_dim = leaf_embeddings.shape[1]\n",
    "    \n",
    "    # --- Initialize models and optimizer ---\n",
    "    agent = TreeBuilder(embedding_dim).to(device)\n",
    "    optimizer = optim.Adam(agent.parameters(), lr=learning_rate)\n",
    "    reward_env = PhylogenticTreeEnv(MockCfgNode({'ENV': {'SEQUENCE_TYPE': 'DNA'}}), DNA_SEQUENCES, device)\n",
    "    \n",
    "    print(\"--- Starting Reinforcement Learning Training ---\\n\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # --- Run one episode (build one tree) ---\n",
    "        \n",
    "        # Reset for the new episode\n",
    "        active_nodes = {i: str(i) for i in range(n_leaves)} # Map index to Newick string\n",
    "        active_embeddings = leaf_embeddings.clone()\n",
    "        \n",
    "        all_log_probs = []\n",
    "\n",
    "        # Build the tree step-by-step\n",
    "        for _ in range(n_leaves - 1):\n",
    "            pair_logits, pair_indices = agent(active_embeddings)\n",
    "            \n",
    "            # Convert logits to a probability distribution and sample an action\n",
    "            action_distribution = Categorical(logits=pair_logits)\n",
    "            chosen_pair_idx = action_distribution.sample()\n",
    "            \n",
    "            # Store the log probability of the chosen action\n",
    "            all_log_probs.append(action_distribution.log_prob(chosen_pair_idx))\n",
    "            \n",
    "            # Get the indices of the nodes to merge\n",
    "            idx1_in_active, idx2_in_active = pair_indices[chosen_pair_idx]\n",
    "            \n",
    "            # Get embeddings for the chosen pair\n",
    "            emb1 = active_embeddings[idx1_in_active].unsqueeze(0)\n",
    "            emb2 = active_embeddings[idx2_in_active].unsqueeze(0)\n",
    "            \n",
    "            # Predict branch lengths and create parent embedding\n",
    "            with torch.no_grad():\n",
    "                branch_lengths = agent.branch_predictor(torch.cat((emb1, emb2), dim=1)).squeeze()\n",
    "                bl1, bl2 = branch_lengths[0].item(), branch_lengths[1].item()\n",
    "                \n",
    "                parent_embedding = agent.parent_embedding_creator(torch.cat((emb1, emb2), dim=1))\n",
    "\n",
    "            # Update active nodes and Newick strings\n",
    "            node1_newick = active_nodes.pop(list(active_nodes.keys())[idx1_in_active])\n",
    "            # The second index shifts after the first pop\n",
    "            node2_newick = active_nodes.pop(list(active_nodes.keys())[idx2_in_active-1])\n",
    "            \n",
    "            new_node_newick = f\"({node1_newick}:{bl1:.4f},{node2_newick}:{bl2:.4f})\"\n",
    "            new_node_id = max(active_nodes.keys()) + 1 if active_nodes else 0\n",
    "            active_nodes[new_node_id] = new_node_newick\n",
    "            \n",
    "            # Update active embeddings\n",
    "            remaining_indices = [i for i in range(len(active_embeddings)) if i not in (idx1_in_active, idx2_in_active)]\n",
    "            active_embeddings = torch.cat((active_embeddings[remaining_indices], parent_embedding), dim=0)\n",
    "\n",
    "        # --- Get Reward ---\n",
    "        final_newick = list(active_nodes.values())[0] + \";\"\n",
    "        reward, status = get_reward(final_newick, DNA_SEQUENCES, reward_env)\n",
    "\n",
    "        # --- Calculate Loss and Update Policy ---\n",
    "        if status == \"OK\":\n",
    "            # REINFORCE loss: -log_prob * (reward - baseline)\n",
    "            # We want to maximize reward, so we minimize the negative\n",
    "            policy_loss = -torch.sum(torch.stack(all_log_probs)) * (reward - reward_baseline)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            policy_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update baseline with moving average\n",
    "            reward_baseline = 0.9 * reward_baseline + 0.1 * reward\n",
    "        \n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Reward: {reward:.4f}, Baseline: {reward_baseline:.4f}, Tree: {final_newick}\")\n",
    "\n",
    "    # --- Inference: Build one final tree greedily ---\n",
    "    print(\"\\n--- Training Finished. Generating final tree greedily ---\")\n",
    "    agent.eval()\n",
    "    active_nodes = {i: str(i) for i in range(n_leaves)}\n",
    "    active_embeddings = leaf_embeddings.clone()\n",
    "    for _ in range(n_leaves - 1):\n",
    "        with torch.no_grad():\n",
    "            pair_logits, pair_indices = agent(active_embeddings)\n",
    "            # Greedily choose the best action\n",
    "            chosen_pair_idx = torch.argmax(pair_logits)\n",
    "            idx1_in_active, idx2_in_active = pair_indices[chosen_pair_idx]\n",
    "            \n",
    "            emb1 = active_embeddings[idx1_in_active].unsqueeze(0)\n",
    "            emb2 = active_embeddings[idx2_in_active].unsqueeze(0)\n",
    "            branch_lengths = agent.branch_predictor(torch.cat((emb1, emb2), dim=1)).squeeze()\n",
    "            bl1, bl2 = branch_lengths[0].item(), branch_lengths[1].item()\n",
    "            parent_embedding = agent.parent_embedding_creator(torch.cat((emb1, emb2), dim=1))\n",
    "        \n",
    "        node1_newick = active_nodes.pop(list(active_nodes.keys())[idx1_in_active])\n",
    "        node2_newick = active_nodes.pop(list(active_nodes.keys())[idx2_in_active-1])\n",
    "        new_node_newick = f\"({node1_newick}:{bl1:.4f},{node2_newick}:{bl2:.4f})\"\n",
    "        new_node_id = max(active_nodes.keys()) + 1 if active_nodes else 0\n",
    "        active_nodes[new_node_id] = new_node_newick\n",
    "        \n",
    "        remaining_indices = [i for i in range(len(active_embeddings)) if i not in (idx1_in_active, idx2_in_active)]\n",
    "        active_embeddings = torch.cat((active_embeddings[remaining_indices], parent_embedding), dim=0)\n",
    "    \n",
    "    final_newick = list(active_nodes.values())[0] + \";\"\n",
    "    final_reward, _ = get_reward(final_newick, DNA_SEQUENCES, reward_env)\n",
    "    print(f\"Final Greedy Tree: {final_newick}\")\n",
    "    print(f\"Final Log-Likelihood: {final_reward:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #run_training()\n",
    "    print(\"Training function is defined. Uncomment run_training() to execute.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de2205b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running the complete training and inference pipeline ---\n",
      "length of DNA sequences: 27\n",
      "Running training with DNA sequences: ['--CCTGGTTGATCCTGCCAGTAGCATA-GCTTGTCTCAAAGATTAAGCCATGCATGTCTAAGTACACACGGCCGGTACAGTGAAACTGCGAATGGCTCATTAAATCAGTTATGGTTCCTT--GTCGCTCCAACCGT---TACTTGGATAACTGTGGT--TTCTA-AGCTAATACATGCCGACGAGCGCTGACCT-C-----------GGGGAT-CGTG-ATTTATCAGACCAAAACCAACGGGCTCGCCCGGCC----------------------------------------------------------------------------------------------GCT-TGGTGACTCTAGATAACC-CGGGCCGATCGCA-GC-CC-CGTGGCGGCGACGACGCATTCGAATGTCT-CCCTATCAACTTTC-ATGGTACTTTCTGTGCCTACCATGGTGACC-CGGGTA-CGGGGA-TCA-GGTTCGATTC-GG-GAGGGA-CCTGAGAAACGGCTACCACATCC-AGGA-GGCAGCA-GCGCG---ATTACCCACTCCCGAC--GGGGA--TAGT-AC-AAAAATAACAATACAGGACTCT---GAGGCCCTGT-ATTGGAATGAGTACACTTTAAATCCTTTAACGAGGA-C-ATTGGAGGGC-AG------------------------------------------------------------------GC-CG-AG---GA-C-TG----------GGATCGAGC--G--GTCCGCCGCGAG-CGACGTACCGCC-GTCCC--GCCCCC-G--TCTCGGCGC-CCCTTGATGCTCTT-AC--AGTGTCCTG--GG-GTCCGAAGCGTTTACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCTGG--TCGCCGGAATACTCCAGCTAGGAATAATGGAATAGGACTCCGGTTCTATTTTGTTGGTTTTCGGAACTGGGGCCATGATTAAGAGGGACGC-C-GG--CATTCGTATTGTGCCGCTAGAGGTGAAATTCTTGGACCGGCGCAAGACGAACCAAAGCGAAAGCATTTGCCAAGAATGTTTTCATTAATCAAGAA-GAAAGTCGG--GTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACTAGCGATCCGGCGGCGTTATT----T-A-CCGCC--GCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCG-GGGGAGTATGGTTGCAAAGCT-AAACTTAAAGGAATTGACGGAAGGGCACCACCAGGAGTGGCA-----GGCTTTATTT-----AACACGGGAAACCTCACCCGGCC-GGACACGGAAAGGA--GACAGATTGATAGCTCTTTCTCGATTCTGTGGGT----GTGCATGGCTGTTCTTAGTTGGTGGAGCGATTTGTCTGGTTAATTCCGATAACGAACGAGACTCT-GGCATGCTAACTAGTTATGCGACCCCC-AGC-GTCGGC-TCC---AA-T-C-TAGAGGGACAAGTGGCGTTCAGCCACCCGAGATTGAGCAATAACA-GTCTGT-ATGCCCTTA-ATGTCCGGGGCTGCA-GCGCGCTACACTGA-CTGGCTCAGCGTGTGTCTACCCTACGCCGACAGGTGCGGGTAACCCGTTGAACCCCATTCGTGA-GGGGA-CGGG-ATTGCAATTATTCCCCA--A-CG-GGAATTCCCAGTAAGTGCGGGTCATAAGCTCGCGTTGATT--G-CCCT-C---TTGT-C-CACCG----TCGCTACTACCGATTGGATGGTTTAGTGAGGTCCTCGGAT-GGCC--GCCGGG-T-GG----CGGCCCT------GCGCCGAGAAGACGGTCGAACT--ACTATCTAGAGGAAGC------------------------------------------------', '----TGGTTGATCCTGCCAGTAGCA---GCTTGTCTC-AAGATTAAGCCATGC-CGTGTAAGTACACACGGCCGGTAC-GTGAAACTGCGAATGGCT--TTAAATC-CTTATGGT--CTTT-ATCGCTCCATCTGT---TACTTGGATAACTGTGGT-ATTCTAGAGCTAATACATGCCGACGAGCGCTGACCTCC-----------CGGGATGCGTGCATTTATCAGACCAAGACCAATGGGCTCGCCCGGCC----------------------------------------------------------------------------------------------GC---GGTGACTCTAGATAACCTCGGGCCGATCGCA-GTCCCCCGTGACGGCGACGATGCATTCGGATGTCTGCCCTATCAACTTTCGATGGTACTTTCTGTGCCTACCATGGTGACCACGGGT--CGGGGAATCAGGGTTCGA-T-CGGAGAGGGAGCCTGAG-A-CGGCT-CCACAT-CAAGGATGGCAGCAGGCG-G---ATTACCCACTCCCGAC--GGGGA--TAGTTA--AAAAATAACAATACAGGACTCTTTCGAGGCCCTGT-ATTGGAATGAGTAC-CTTT-AATCCTTTAACGAGGATCCATTGGAGGGCAAGTCTGGTGCTAGCAGC-GCGG---TTCCAGCTCCAATAGCGTATATTAAAGTTGCTGCAGT-AAAAAGCTCGTAG---GATCTTG----------GGATCGAGCTGG--GTCCGCCGCGAGGCGACG-ACCGCCTGTCCCA-GCCCCC-G--TCTCGGCGCCCCCTTGATGCTCTTGACTGAGTGTCCTG--GG--CCCGAA-----TACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCCGG--TCGCCTGAATACTTCAGCTAGGAATAATGGAATAGGACTCCGGTTCTATTTTGTTGGTTTTCGGAACTGGGGCCATGATT--G-GGG-CG-C-GGGGGCATTCGTATTGTTCCGCTAGAGGTGAAATTCTTGGACCGGCGCAAGACGAACCAAAGCGAAAGCATTTGCCAAGAATGTTTTCATTAATCAAGAACGAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACTAGCGATCCGGCGGCGTTATTCCCATGACCCGCCGAGCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTAGGGT------------------------------------------------------------------------AACACGGGAAACCTCACCCGGCCCGGACACGGAAAGGA--GACAGATTGATAGCTCTTTCTCGATTCTGTGGGT----GTGCATGGCTGTTCTTAGTTGGTGGAGC-ATTTGTCTGGTTAATTCCGATAACGAA-GAGACT-C-TCCATGCTAACTAGTTACGCGACCCCCA-GCGGTCGGCGTCC---AACTTCTTAGAGGGACAAGTGGCGTTCAGCCACACGAGAT-GAGCAATAACA-GTCTGT-ATGCCCTTAGATGTCC----CTGCACGCGCGCTACACTGA-ACGGATCAGCGTGTGTCTACCCTTCGCCGACAGGT-CGGGTAACCCGCT-AACCCCGTTCGTGATAGGGATTGGGGATTGCAATTATTTCCCATGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGCTCGCGTTGATT--GTCCCT-CCC-TTGTAC-CAC------TCGCTACTACCGATTGGATGGTTTAGTGAGGTCCTCGGATCGGCCCCGCCGGGGTCGG-CATCGGCC-------AGTGCCGAGAAGACGATCAAACT-GACTATCTAGAGGAAG-------------------------------------------------', '--CCT-GTTGATCCTGCCAG-AGCA---GCTTGTCTCAAAGATTAAGCCATGCACGTGTAAGTACACACGGCCGGTACAGTGAAACTGCGAA--------TAAATCAGTTAT----------ATCGCTCCATCT-T---TACTTGGATAACTGT-GTTATTCTT-AGCTAATACATGCCGACGAGCGCTGACCTCC-----------CGGGATG-GTGCATTTATC-GACCAAAACCAATGGGCTCGCC---CC----------------------------------------------------------------------------------------------GC---GGT-ACTCTAGATAACCTCGGGC-GATCGCA-G-C-CCCGTGACGGCGACGA------------------------------------------------------------------------------------------CGGAGAGGGAGCCT-AG-AACGGCT-CCACAT-CAAGG--GGCAGCAGGCGC----ATTACCCACTCC-GACCCGGGGA--TA-T-A--AAAAATAACAATACAGGACTCTTTCGAGGCCCTGT-ATTGGAATGAGTACACTTT-AA-CCTTTAACGAGGATCCATTGGAGGGCAAGTCT-GTGCC-GCAGCCGCGG--ATTCCAGCTCCAAT-G-GTATATT-AAGTTGCT-CAGTT--AAAGCTCGTAGTT-GATCTTG----------GGATCGAGCT----GTCCGCCGCGAGGCGACG--CCGC--GTCCCA-GCCCC--G--TCTCGGCGCCCCCTCGATGCTCTTGACTGAGTGTCTTG--GG---CCGAAG----TACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCCGG--TCGCCTGAATACTTCAGCTAGGAATAATGGAATAGGACTCCGGTTCT-TTTTGTT-GTTTTCGGAACTGGGGCCATGATTAAGAGGGAGGGACG-------TCGTATTGTGCCGCTAGAGGT-AAATTCTT-GACCGGCGCAAGACGAACCAAAGCGAAAGCATTTGCCAAGAAT-T--TCATTAATCAAGAATGAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGT-GTTCCGACCATAAACGATGCCGACT-GCGATCCGGCGGCGTT-TTCCCATGACCCGCTT-GCAGCTTCCGGGAAACCAAAGTCTTTGG---CCGGGGGGAGTATGGTTGCAAAGCT-AAACTT--------------------------------------------------------AACACGGGAAACCTT-CCCG-CCCGGAC-CGGAAAGGA---AC-GATTGATAGCTCTTTCTCGATTCTGTGGGTT-TTTTGC-TGGCT-TTCTT-GTTGGTGGAG--ATTTGTCT-GTT-ATTCCGATAACGA-TGAGACTTC-TCCATGCT-ACTAGTTACGCGACCCCCA-GC-GTCGG--T-----T--TT-TTAGAGGGACTAGTGGCGTTCAGCC-CACGAGATCGAGCAATAACA-GTCTGT-ATGCCCT-AGATGTCC----CT-CACGCGCGCT-CACT-A-ACGGATCAGCGT-TGTCTACCCTTCGCCGACAGG---GGG--ACCC-CT-AACCCC-TT-GT-ATAGGGATCGGGGATTGCAATTATTTCCCATGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGC-GCTGTT-A----GTCCC--CC-TTTGTACACAC------TCGCT-CTACCGATTGGAT-GTTTAGT-AGGT-CT-G-AGTTGGCC---TGGGGTTGG--AT-GC-TT-----GCGTCCGTAGAAGACGATCAAACT--ACTATCTAGAGGAAG-------------------------------------------------', '---------------------------------------------AGCCATGCACGTGTAAGTACGCACGGCCGGTACAGTGAAACTGCGAATGGC--------------------------ATCGCTCCAACCGT---TACTTGGATAACTGTGGTAATTCTAGAGCTAATACATGCCGACGAGCGCTGACCCCC-----------AGGGATGCGTGCATTTATCAGACCAAAACCAATCGGGG---GGGCGC-CGGG-C--GG--T-GGGGGTGGTCT-GGCCTCCC--C-CAGCC-C--C-GCTCTCCC--G-C-------------------------------GCTTTGGTGACTCTAGATAACCTCGGGCCGATCGCACGTC-CCCGTGACGGCGACGATCCATTCGGATGTCTGCCCTATCAACTTTCGATGGTACTTTCTGCGCCTACCATGGTGACCACGGGTAACGGGGAATCAGGGTTCGATTCCGGAGAGGGAGCCTGAGAAACGGCTACCACATCCAAGGA-GGCAGCAGGCGC-CA-ATTACCCACTCCCGAC-CGGGGAG-TAGTGACGAAAAATAACAATACAGGACTCTTTCGAGGCCCTGTAATTGGAATGAGTACACTTTAAATCCTTTAACGAGGA-CTATTGGAGGGC-AGTCTGG----------------------------------GTATATTAAAGTTGCTGCAGTT--AAAGCTCGTAG---GATCTTG----------GGATCGAGCT-G--GTCCGCCGCGAGGCGAC---CCGCC-GTCCCA-GCCCCC-G--TCTCGGCGCCTCCC--ATGCTCTTGACTGAGTGTCCCG--GGG-CCCGAA-----TACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCCGGG-TCGCCTGAATACTTCAGCTAGGAATAATGGAATAGGACTCCGGTTCTATTTTGTTGGTTTTCGGAACTGGGGCCATGATTAAGAGGGACG---------ATCCGTATTGCGCCGCTAGAGGT-AAATTCTTGGACCGGCGC-AGACGAACCAAAGCGAAAGCATTTGCCAAGAATGTTTTCATTAATCAAG-A-GAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACCGG--ATCCGG-GG--TTATTCCCATGACCCGCCGAGCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCTGAAACTTAAAGGAATTGACGGAAGGGCACCACCAGGAGTGGCAG--GCGGCTT-ATTT-----AACACGGGAAACCTCACCCGGCCCGGACACGGAAAGGAT-GACAGATTGATAGCTCTTTCTCGATTCTGTGGG------TGCATGGC----CTTAGTTGGTGGAGC-ATTTGTCT-GTT-ATTCCGATAACGAATGAGACT-C-TCCATGCT-ACTAGTTACGCGACCCC-------TCCGCGTCC---AACTTCTTAGAGGGACAAGTGG-GTTCAGCCACGCGAGATCGAGCAATAACAAGTCTGTGATGCCCTTAGATGTCC----CTTCAC--GCGCT-CACT-A-ACGGACCAGCGTGTGTCTACCCTTCGCCGACAGGTCGGGGT-ACCCGCTGAACCCCGTTCGTGATAGGGATCGGGGATTGCAATTATTTCCCATGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGCTCGCGTTGATT--GTCCCT-CCCTTTGTACACACCGC---TCGCTACTACCGATTGGATGGTTTAGTGAGGTCCTCGGATCGGCCCCGCCGGGG-CGG-CGACGGCCC----G-AGCGCCGAGAAGACGATCAAACT--ACTATCTAGAGGAAG-------------------------------------------------', '----TGGTTGATCCTGCCAGTAGCATA--C-TGTCTCAAAGATTAAG-CATGCACGTGTAAGTACACACGGCCGGTACAGTGAAACTGCGAATGGCT----AAATCAGTTATGGT--CT---ATCGCTCCATCTGT---TACTTGGATAACTGTGGT-ATTCT-GAGCTAATACATGCCGACGAGCGCTGACCC--------------GG-ATGCGTGCATTTATCAGACCAAAACCAATGGGCACTCGTGCC--G-C------------------------------------------------------------------------------------------GCTTTGGT-ACTCTAGATAACCTCGGGC-GATCGCACGTC-CCCGTGACGGCGACGATACATT--------------------------------------------------------------------------------------------------------------------------------------------ATT-CC--CTCC-G-CT-GGG-------T-AT-AAAAATAACAATACAGGACTCTTTCGAGGCCCT-TTATTGGAATGAGTACACTTT----CCTTTAACGAGGATCTATTGGA-TGCAAGTC-------------------------------------GTATATT-AAGTTGCTGCAGT---AAAGC--GTAGT--GATCTTG----------GGATCGAGCT----GTCCGCCGC-AGG-GACG--CCGC--GTCCCA-GCCCCC-G--TCTCGGCGCCTCCCC-ATGCTCTTGACTGAGTGTCCCG--GG---CCGAAG----TACTTTGAAAAAATTA-A-TGTTCAAAGCAGGCC-G--TCGCCTGAATAC-TCAGCTAGGAATAATGGAATA-GACTCCGGTTCT-TTTTGT-GGTTTTCGGAACTGGGG---TGATTAAGAGGGACG-CC-------TTCGTATTGTGCCGCTAGAGGT-AAATTCTTGGACCGGCGCAAGACGAACCAAAGCGAAAGCATTTGCCAAGAAT-TTTTCATTAATCAAGAA-GAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACTAGCGATCCGGCGG-GTTATTCCCATGACCCGC--AGCAGCTTCCGGGAAACCAAAGTCTTTGGG-TCCGGGGGGAGTATGGT------------------------------------------------------------------------AACAC-GGAAACCT-ACCCGGCCCGGACACGGAAAGGA--GACAGATTGATAGCTCTTTCTCGATTCTGTGGGT-----TGCATGGC--TTCTTAGTTGGTGGAG--ATTTGTCTGGTTAATTCCGATAACGA-TGAGACT-C-TCCATGCTAACTAGTTACGCGACCCCCA-GCGGTCGGCGT-C---AAC---TTAGAGGGACAAG-GGCGTTCAGCCACACGAGAT-GAGCAATAACA-GTCTGTGATGCCCTTAGATGTCC----CTGCACGCGCGCTACACTGA-ACGGATCAGCGTGTGTCTACCCTTCGC-GACAGG---GGG-AACCCGCTGAACCC-GT-C--GAAAGGGAAAGGGGA--GCAATTATTTCCCAT-AACGAGGAATTCCCAGTAAGTGCGGG-CATAAGCT-GCGTTGAT---GTCCCT-CCCTTTGTAC-CACTT----T-GCT-CTACCGATTGGATGGTTTAGTGAGGTCCTCGGGGT-GGGCCCCCGGGGTCGG-C-ACGGCCCT------GCGCCGAGAAGACGATCAAACT------------------------------------------------------------------', '--CCTGGTTGATCCTGCCAGTAGCA---GCTTGTCTCAAAGATTAAGCCATGCACGTGTAAGTACACACGGCCGGTACAGTGAAACTGCGAATGGC----TAAATCAGTTATGG---CTT--ATCGCTCCAACCG-----AC-----------------------------------------------------------------AGGGATG-GTGCATTTAT-AGACCAAAACC--T-GGGT-T-GC-----GGGGC--AAGGG-----G-T-CTCCCCGGGA---G-GCCCGG---G--GG-CCG-----CC----G---------------------------GCCTTGGCGACTCTAGATAACCTCGGGC--ATCGCACGTC-CCCGTGACGGCGACGATCCATTCGGACGTCTGCCCTATCAACTTTCGATGGTACTTTCTGCGCCTACCATGGTGACCACGGG--ACGGGGAATCAGGG-T-GAT--CGGAGAG-GAGCCTGAGAAACGGCT-CCACAT-CAAGGA-GGCAGCAGGCGCGC--ATTACCCACTCC-GACG-GGGGA--TAGTGA--AAAAATAACAATACAGGACTCTTTCGAGGCCCTGT-ATTGGAATGAGCACACTTTAAA-CCTTTCACGAGGA-CC-TTGGAGG-C-AGTCT------A--AG--G-GG---TTCCAGCTCCAA----GTATATTAAAGTTGC-GCAGTT--AAAGCT-GTAG---GATCTTG----------GGATTGAGCT-C--GTC-GCCGAAAGGCGACG--CCGC--GTCCCA-GCC-------TCTCGGCGCC-CTCCGATGCTCTTGACTGAGTGTCCCGTGCGGGCCC-AAG----TACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCC------GCCTGAATACTTCAGCTAGGAATAATGGAATAGGACTCCGGTTCT-TTTTGTT-GTTTTCGGAACTGGGGCCATGATTAAGAGGG--------------TCGTATTGTGCCGCTAGAGGTGAAATTCTTGGACCGGCGCAAGACGAACCAAAGCGAAAGCATTTGCCAAGAAT-TTTTCATTAATCAAGAA-GAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACTAGCGATCCGGCGGCGTTTTTCCCATGACCCGCCGG-CAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCT-AAACTTAA------------------------------------------------------AACACGGGAAACCTCACCCGGCCCGGACACGGAAAGGATT-ACAGATTGATA-------------------------------------------GTTGGTGGAG---TTTGTCT-GTT-ATTCCGATAACGAT-GAGACT-C-CC-ATGCT-ACTT-T--CGCGACCCCC------TCC-CGTCC----GCT--TTA--GGGACAA----CGTTCAGCCACGCGAGATCGAGCAATAACA-GTCTGT-ATGCCCTTAGATGTCC----CTGCACGCGCGCT-CACTGA-ACGGACCAGCGTGTGTCTACCCTTCGCCGACAGGTCCGGG--ACCCGCT-AACCCCGTT-GTGATAGGGA--GGGGATTGCAATTATTTCCCATGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGCT-G--TTGATT--GTCCCT-C--TTTGTACACAC------TCGCTACTACCGATTGGATGGTT-AGTGAGGT-CTCGGAT-GGCCCCC--GGGGT-GC-C--CGGCCCT-----AGCGCCGAGAAGACGATCAAACT--ACTATC----------------------------------------------------------', '--CC-GGTTGATCCTGCCAGTAGCA---GCT-GTCTCAAAGATTAAGCCATGCATGTCTAAGTACACACGGGCGGTACAGTGAAACTGCGAATGGC-----AAATCAGTTATGG---------TCGCTCCCCTCCC----ACTTGGATAACTGT-G----TCT-GAGCTAAT-CATGCCGACGAGCGCCGACCTCC-----------GGG-ACG-G--CATTTATCAGACCAAAACCAACGG-C-CGCCC--------------------------------------------------------------------------------------------------G---TGG--ACTCTAGATAACCTCGAGCCGATCGCA-GC-CCC--TGGCGGCGACGACCCATT--AATGTC--CCCTATCAACTT-CGATGGTACTGTCTGTGCCTACCATGGTG---ACGGGTAACGGG-AATCAGGGTTCGAT--CGGAGAGGGAGCCTGAGAAACGGCT-CCACATCCAAGGA-GGCAGCAGGCGCGC--ATTACCCACTCCCGACCCGGGGA--T-GT-AC-AAAAATAACAATACAGGACTCTTTCGAGGCCCT-T-ATTGGAATGAGTCCACTTTAAAT--TTTAA-GAGGA-CCATTGGAGGG-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ACTTTGAAAAAATTAGAGTGTTCAAAGCA--------CCGCCGGAAT-CTCCAGCTAGGAATAA-GGAATAGGACTCC-GTTC--TTTTGTT-G-TTTCGGAAACGGGGCCATGATTAAGAGGGACGGC-GGGGG-ATTCGTATTGTGCCGCTAGAGGT-AAATTCTTGGACCGGCGCAAGACGAACTAAAGCGAAAGCATTTGCCAAGAATGT--TCATTAATCAAGAA-GAAAGTCGGAGGTTCGAAGACGATCAGATACCGT-GTAGTTCCGACCATAAACGATGCCGAC-AGCGATCCGG--G----ATTCCCAT-ACCCGC-----AGCTCCCGGGAAACCCAAG-----GGG-------------------------------------------------------------------------------------------ACACGGGAAACCT-ACCCG-CC-GGACACGGACAGGAT--ACAGATTGAGAGCTCTTTCTCGATTCCGTGGGT--T---GCATGGC----CTTAGTTGGTGGAGC--TTTGTCT-GTT-ATTCCGATAACGA--GAGACTCT-GGCATGCT-ACTAGTTACGCGACCC--GAGC-GTCGG--TCC---A----CGTAGAGGGACAAGTGGCGTTCAGCCACCCGAGATTGAGCAATAACA-GTCTGTGATGCCCTTAGATGTCCG---CTGCACGCG--CT-CACTGA-CTGGCTCAGCTTGTGTCTACCCT--GCCGG-AGGCGCGGG--ACCCGTTGAACCCCATTCGTGATGGGGATCGGG-ATTGCAATTATTCCC-ATGAACGAGGAATTCCCAGTAAGTGCGGGT-ATAAGCT-GCGTTGATT--GTCCCT-C---TTGTACACAC-G----TTGCTACTACCGATTGGATGGTTTAGTGAGGT-CTTGGAT-GGC-CTGG-GGGGT-G---C--GGC--TG-----G-G--GAGGAGA-GGTCGA--T--ACTATCTAGAGGAAG-------------------------------------------------', '---CTGGTTGATCCTGCCAGTAGC----GCTTGTCTCAAAGATTAAGCCATGC-CGTGTAAGTACACACGGAC-GTACAGTGAAACTGCGAATGGC---TTAAATCAGTTATGG---CTT--ATCGCTCCCAT---T--TACTTGGATAACTGTGGTAATTCT-GAGCT-ATACATGCCGA-GAGCGCTGACCCCC-----------AGG-ATGCGTGCATTTATCAGACCAAAACCAATCGGGGGC-C--G-GTC---G-CCC----CCC--G----------------------------------------------------------------------------TTTGGCGACTCTAGATAACCTCGGGC-GATCGCA-GTC-CCCGTGACGGCGACGATACTTTCGGATGTCTGCCCTATC-ACTTTC-AT-GTTCTTTCT-CGC-TACCAT-GTGACCACGGGT-A-GGG--ATCAGG--T---T--CGGAGA--GAGCCT-AG-AACGGCT-CCACAT-CAAGG--GGCAGCAGGCGC-C--ATTACCCACTCC-GACT-GGG-A----GT-A--AAAAATAACAATACAGGACTCTTTCGAGGCCCTGT-ATTGGAATGAGTACACTTT-A--CCTTTAACGAGGACCCATTGGAGGGCAAGTCT-GTGCC-GCAGCCGCGG--ATTCCAGCTCCAATA--GTATATTAAAGTTGCTGCAGTT--AAAGCTCGTAGTT-GATCTTG----------GGAT-GAGCT----GTCCGCCGCGAGGCGACG--CCGC--GTCCCA-GCCCCC----TCTCGG--CCTCCCC-ATGCTCTT-----AGTGTCCCG--GGGGCCCGAAG-G--TACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCCGG--TCGCC-GAATACTT--GCT-GGAATA-TGGAATAGGACTCCGGT-CT-TTTTGTT-GTTTTCGGAACTGGGG--AT-ATT-AGAGGGAC-------------CGTATTGTGCCGCTAGAGGT-AAATTCTTGGACCGGCGCAAGACGAACCAAAGCGAAAGCATTTGCCAAGAATGTTTTCATTAATCAAGAA-GAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGT-GTTCCGACCATAAACGATGCCGAC-AGCGATCCGGCGG--TTTTTCCCATGACCCGCC-AGCAGCTT-CGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCT-AAACTTAAAGGAA----------------------------------------------------ACGGGAAACCTCACCCGGCCCGGACACGGAAAGGA---ACAGATTGATAGC------------------------TTGAATGGCTTTTTTT-GTTGGTGGAGCGATTTGTCT-GTTTATTCCGATAACGAT-GAGACTCC-C-CATGCT-A-T--T--CGCGACCCCC----GTCCGCGT------GC---TTAGAGGGACCAAGTGGCGTTCAGCCACACGAGATCGAGCAATAACA-GTCTGTGATGCCCTTAGATGTCCGG--CTGCACGCGCGCT-CACTGA-ACGGACCAGCGTGTGTCTACCCTT-GC-GACAGGT--GGG--ACCCGCT-AA-CCCGTT-GTGATAGGGATCGGGGACTGCAATTATTTCCCATGA-CGAGGAATTCCCAGTAAG-GCGGGTCATAAGCT-GCG-TGATT--GTCCCT-CCC-TTGTACACAC--C---TCGCTACTACCGATTGGATGGTTTAGTGAGGTCCTCGGATCGGCCCCC--GGGG---G-CCACGGCCC-G----AGCGCCGAGAAGACGATCAAACT--A---------------------------------------------------------------', '--CCT-GTT-ATCCT-CCAG-AGCA---GCT-GTCTCAAAGATTAAGCCATGCACGTGTAAGTACACACGGCCGGTACAGTGAAACTGCGA-------------------------------ATCGCTCCATC-CGT--TACTTGGATAACTGTGGT-ATTCT--A-CT-ATACATGCCGACGAGCGCT-ACCTCC-----------CGGGATG-GTGCATTTATCAGACC--AACCAATGGGCTCGCC---CC----------------------------------------------------------------------------------------------GC---GGT-ACTCT-GATAACCTCGGGC--AT-GCACGTC-C--GTGACGGCGACGATACATTCGGATGTC-GCCCTATC-ACTTTCG-TGGT-CTTTCTGCGCCTACCATGGTGAC-ACGGGTAACGGGGAATC-GGGTT--TTT--GGAGAG-GAGCCT-AG-AACGGCT-CCACAT-CAAGG-TGGC-GCAGGCGC----ATTACCC-CTCC-GACT-GGGGA--T--T-AT-AAAAATAACAATACAGG-CTCTTTCGAGGCCCTGTTATTGGAATGAGTACACTTT----CCTTTAACGAGGATCC-TTGGA---CAAGTCT-GTGCC-GCAGC-GCG---ATTCCAGCTCCAAT---GTATATT-AAGTTGCT-CAGTT--AAAGCTCGTAGTT-GATCTTG----------GGATCGAGCT----GTCCGCCGCGAGGCGAC---CCGC--GTCCCA-GCCCC--G--TCTCGGCGCCTCCTTGATGCTCTTGACTGAGTGTCCTG--GGG--CCGAAG----TACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCC-G--TCGCCT-AATACTTCAGCTAGGAATAATGGAATAGGACTCCGGTTCT-TTTTGTT-GTTTTCGGAACTGGGGCCATGATTAAGAGGGA------------TTCGTATTGTGCCGCTAGAGGT-AAATTCTT-GACCGGCGCAAGACGAACCAAAGCGAAAGCATTTGCCAAGAAT-T--TCATTAATCAAGAA-GAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGT-GTTCCGACCAT-AACGATGCCGACT-GCGATCCGGCGG-GTT-TTCCCATGACCCGC---GCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCT-AAAC----------------------------------------------------------AACACGGG--ACCT--CCCGGCCCGGACACGGAAAGGA---ACAGATTGATA--------------------------TTGCATGGCT-TTCTT-GTTGGTGGAGC--TTTGTCT-GTT-ATTCCGATAACGA-TGAGACT-C-TCCATGCT-ACTAGTTACGCGACCCCCA-GCGGTCGG--T-C---------TTAGAGGGACAA-T----TTCAGCCACACGAGATCGAGCAATAACA-GTCTGT-ATGCCCT-AGATGTCC----CTGCACGCGCGCT-CACT-A-ACGGATCAGCGT-TGTCTACCCTTCGCCGACAGG---GGG--ACCCGCT-AACCCC----GT-ATAGGGATCGGGGATTGCAATT-TTTCCCAT-AACGAGG-ATTCCC-GTAAGTGCGGG-CATAAGCT-GCGTTGA------CCCC-CC--TTGTACACAC------TCGCT-CTACC-ATT-GAT-GTTTAGT-AGGT-CTCGGAT-GGCCCCC--GGGG--GG-CG-CGGCC-T-----CGCGCCGAGAAGA--ATCAAACT--ACTA------------------------------------------------------------', '--CCT-GTTGATCCTGCCAG-AGCA---GCT-GTCTCAAAGATTAAGCCATGCATGTCTAAGTACACACGGGCGTGACAGTGAAACTGCGAATGGC----TAAATCAGTTATGG---CT---GTCGCTCCCACCGT---TACTCGGATAACTGTGG----TCTAGAGCTAATACATGCCGACGAGCGCTGACCTCC-----------GGGGATGCGTGCATTTATCAGACCAAAACCAACGGGCT--CCCGGCC----------------------------------------------------------------------------------------------GCT-TGGTGACTCTAGATAACCTCGGGCCGATCGCA-GCCCCCCGTGGCGGCGACGACGCATTCGAACGTCTGCCCTATCAACTTTCGATGGTACTTTCTGTGCCTACCATGGTGACCACGGGTAACGGGGAATCAGGGTTCGATTCCGGAGAGGGAGCCTGAGAAACGGCTACCACATCCAAGGA-GGCAGCAGGCGCG---ATTACCCACTCCCGAC-CGGGGA--TAGT-AC-AAAAATAACAATACAGGACTCTTTCGAGGCCCT---ATTGGAATGAGTCCACTTTAAATCCTTTAACGAGG--CCATTGGAGGGC-AG-----------------------TT-CAGCTCCAATAGCGTATATTAAAGTTGCTGCAGT--AAAAGCTCGTAG---GATCTTG----------GGA-CGAGCTGG--GTCCGCCGCGAGGCGA-CGACCGC--GTCCCA-GCCCCT-GCCTCTCGGTGCTCCCCCGATGCTCTTAACTGAGTGTCTCG--GG---CCGAAGC---TACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCCGG--TCGCCGGAATACTCCAGCTAGGAATAATGGAATAGGACTCCGGTTCTATTTTGTTGGTTTTCGGAACCGG-GCCATGATTAAGAGGGACG--C-G-----TTCGTATTGTGCCGCTAGAGGT-AAATTCTTGGACCGGCGCAAGACGACCCAGAGCGAAAGCATTTGCCAAGAAT-TTTTCATTAATC-AG-A-GAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACTAGCGATCCGGCGG-GTTATTCCCATGACCCGCC-AGCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAG-ATGGT----------AAACTTAAAGGAATTGACGGAAGGGC-CCACCAGGAGTGGCAG--GCGGCTT-AT-------AACACGGGAAACCTCACCCGGCCCGGACACGGAAAGGA---ACAGATCGATAGCTCTTTCTCGATTCTGTGGGT-GT-GTGCATGGC---TCTTAGTTGGTGGAGCGATTTGTCTGGTTAATTCCGATAACGAACGAGACTCT-GGCATGCTAAC-AGTTATGCGACCCCC-AGCGGTCGG--TCC---AA----TTA-AGGGACAAGTGGCGTTCAGCCACCCGAGATT-AGCAATAA-A-GTCTGT-ATGCCCTTAGATGTC-----CTGCACG-GCGCT-CACTGA-CTGGCT-AGCGT-TGTCTACCCTACGCCGACAGGTGCGGGT-ACCTGTTGAACCCCATTCGTGATGGGGATCGGGGATTGCAATTATTCCCTATGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGCT-GCGTTGATT--GTCCCT-C--TTTGTACACACCT----T-GCTACTACCGATTGGATGGTTTAGTGAGGT-CTTGGAT-GGCCCTG-CGGGGTTGG-CCT-GGCCCT------GCGCCGAGAAGACGGT-GAAC---ACTATCTAGAGGAAG-------------------------------------------------', 'TACCTGGTTGATCCTGCCAGTAGCATATGCTTGTCTCAAAGATTAAGCCATGCATGTCTAAGTACGCACGGCCGGTACAGTGAAACTGCGAATGGCTCATTAAATCAGTTATGGTTCCTTTGGTCGCTCGCTCCTCTCCTACTTGGATAACTGTGGTAATTCTAGAGCTAATACATGCCGACGGGCGCTGACCCCC-TTCGCGGG--GGGGATGCGTGCATTTATCAGATCAAAACCAACCCGGTCAGCCCCTCTCCGGCCCCGGCCGGGGGGCGGGCCGCGGCG---------------------------------------------------------------GCTTTGGTGACTCTAGATAACCTCGGGCCGATCGCACGCCCCCCGTGGCGGCGACGACCCATTCGAACGTCTGCCCTATCAACTTTCGATGGTAGTCGCCGTGCCTACCATGGTGACCACGGGTGACGGGGAATCAGGGTTCGATTCCGGAGAGGGAGCCTGAGAAACGGCTACCACATCCAAGGAAGGCAGCAGGCGCGCAAATTACCCACTCCCGACCCGGGGAGGTAGTGACGAAAAATAACAATACAGGACTCTTTCGAGGCCCTGTAATTGGAATGAGTCCACTTTAAATCCTTTAACGAGGATCCATTGGAGGGCAAGTCTGGTGCCAGCAGCCGCGGTAATTCCAGCTCCAATAGCGTATATTAAAGTTGCTGCAGTTAAAAAGCTCGTAGTTGGATCTTG----------GGAGCGGGCGGGCGGTCCGCCGCGAGGCGAGCCACCGCCCGTCCCC-GCCCCTTGCCTCTCGGCGCCCCCTCGATGCTCTTAGCTGAGTGTCCCG-CGGGGCCCGAAGCGTTTACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCCCGAGCCGCCTGGATACCGCAGCTAGGAATAATGGAATAGGACCGCGGTTCTATTTTGTTGGTTTTCGGAACTGAGGCCATGATTAAGAGGGACGGCCGGGGGCATTCGTATTGCGCCGCTAGAGGTGAAATTCTTGGACCGGCGCAAGACGGACCAGAGCGAAAGCATTTGCCAAGAATGTTTTCATTAATCAAGAACGAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACCGGCGATGCGGCGGCGTTATTCCCATGACCCGCCGGGCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCTGAAACTTAAAGGAATTGACGGAAGGGCACCACCAGGAGTGGAGCCTGCGGCTTAATTTGACTCAACACGGGAAACCTCACCCGGCCCGGACACGGACAGGATTGACAGATTGATAGCTCTTTCTCGATTCCGTGGGTGGTGGTGCATGGCCGTTCTTAGTTGGTGGAGCGATTTGTCTGGTTAATTCCGATAACGAACGAGACTCT-GGCATGCTAACTAGTTACGCGACCCCCGAGCGGTCGGCGTCCCCCAACTTCTTAGAGGGACAAGTGGCGTTCAGCCACCCGAGATTGAGCAATAACAGGTCTGTGATGCCCTTAGATGTCCGGGGCTGCACGCGCGCTACACTGA-CTGGCTCAGCGTGTGCCTACCCTACGCCGGCAGGCGCGGGTAACCCGTTGAACCCCATTCGTGATGGGGATCGGGGATTGCAATTATTCCCCATGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGCTTGCGTTGATTAAGTCCCTGCCCTTTGTACACACCGCCCGTCGCTACTACCGATTGGATGGTTTAGTGAGGCCCTCGGATCGGCCCCGCCGGGGTCGGCCCACGGCCT-GGCGGAGCGCTGAGAAGACGGTCGAACTTGACTATCTAGAGGAAGTAAAAGTCGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTA', '--CCTGGTTGATCCTGCCAGTAGCA-A--C-TGTCTCAAAGATTAAGCCATGCACGTGTAAGTACACACGGCCGGTACAGTGAAACTGCGAATGGCT--T-AAATCAGTTAT-----CT---ATCGCTCCAACC------CCTTGGATAACTGT-GT-ATTCT--AGCT-ATACATGCCGACGAGCGCTGACCACC-----------AGGGACGCGTGCATTTATCAGACCAAAACCAATCGGGGGCCCGGG-GCGGCGG-GGCGGAGGGG-GGCTCT-AAAAGCC------C-C---C--GCTCTCCC--G-C----------------------------------GCCTTGGCGACTCTAGATAACCTCGGGCCGATCGCACGTC-CCCGTGACGGCGACGACGCATTCGGATGTCTGCCCTATCAACTTTCGATGGTACTTTCTGCGCCTACCATGGTGACCACGGGTAACGGG-AATC-GGGT-CG-TTCCGGAGAGGGAGCCTGAGAAACGGCT-CCACATCC--G---GG--GC-GGCGCGC--ATT-CC--CTCCCGAC--GGGGA--T-GT-A--AAAAAT-AC-ATACAGGACTCTTTCGAGGCCCTGT-ATTGGAATGAGTACACTTTAAATCCTTTAACGAGG--CTATTGGAGGG-A-GT----------------------TTCCAGCTCCAATA--GTATATTAAA---GTTGCAG-T--AAAGCTCGTAGT--GATCTTG----------GGATCGAGCTGG--GTCCGCCGCGAGGCGAC--ACCGCC-GTCCCA-GCCCCC-G--TCTCGGCGCCCCTCCGATGCTCTTGACTGAGTGTCCCG--GGGGCCCGAAGC---TACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCCGG--TCGCCTGAATACTTCAGCTAGGAATAATGGAATAGGACTCCGGTTCTATTTTGTT-GTTTTCGGAACTGGGG--ATGATTAAGAGGGAC--C--------TTCGTATTGTGCCGCTAGAGGTGAAATTCTTGGACCGGCGCAAGACGGACCAAAGCGAAAGCATTTGCCAAGAATGTTTTCATTAATCAAGAACGAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACTAGCGATCCGGCGGCGTTATTCCCATGACCCGCCGAGCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCT---------------------------------------------------------------AACA-GGGAAACCT-ACCCG-CCCGGA-A-GGAAAGGA--GACAGATTGATAGCTCTTTCTCGATTCTGTGGGT----GTGCATGGC----CTTAGTTGGTGGAGCGATTTGTCTGGTT-ATTCCGATAACGAATGAGACT-C-TCCATGCTAACTAGTTACGCGACCCCCG----GTCCGCGTCC---AACTT-T-AGAGGGACAAG-GGCGTT-AGCC-CACGAGATCGAG-AATAACA-GTCTGT-ATGCC-TTAGATGTCC------GCACGCGCGCTACACTGA-ACGGACCAGCGTGTGTCTACCCTTCGCCGACAGGTCGGGG--ACCCGCT-AACCCCGT-CGTGATAGGGATCGGGGATTGC-ATTATTTCCCATGAACGAGG-ATTCCCAGTAAGTGCGGG-CATAAGCTCGCGTTGATT--GTCCCT-CC-TTTGTAC-C-CCGC----CGCTACTACCGATTGGATGGTTTAGTGAGGTCCTCGGATCGGCCCCGGCGGGGTCGG-CGACGGC---GGCGGAGCGCCGAGAAGACGATCAAAC---ACTATCTAGAGGAAGT------------------------------------------------', '--------------------------------------------------------------------------------------------------------------------------ATCGCTC-ATCTCGT--TACTTGGATAACTGTGGT-ATTCT-GAGCT-ATACATGCCGACGAGCGCT-ACCTCC-----------CGGGATG-GTGCATTTATCAGACC--AACCAATGGGCTCGCC---C-----------------------------------------------------------------------------------------------GCT--GGT-ACTCTAGATAACCTCGGGCCGATCGCACGTC-CCCGTGACGGCGACGATACA------------------------------------------------------------------------------------------------------------------------------GGC-GCAGGCG--C--ATTACCCACTCC-GACTCGGGGA-----T-A--AAAAATAACAATACAGGACTCTTTCGAGGCCCTG--ATTGGAATGAGTACACTTT----CCTTTAACGAGGAGCCA----A---CAAGTCTGGTGCC--CAGC-------ATTCCAGCTCCAAT---GTATATT-AAGTTGCT-CAGTT--AAA-CT-GTAG---GATCTTG----------GGAT-GAGCT----GTC-GC-GCGAGGCGACG--CCGC--GTCCCA-GCCC---G--TCTCGGCGCCTCCTTGATGCTCTTGACTGAGTGTCCTG--GGGG-CCGAAG----TACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCC-G--TCGCCTGAATACTTCAGCTAGGAATAATGGAATAGGACTCCGGTTCT-TTTTGTT-GTTTTCGGAACTGGGGCCATGATTAAGAGGG----------------------TGCCGCTAGAGGT---ATTCT--GACCGGCGCAAGACGAACCAAAGCGAAAGCATTTGCCAAGAAT-T--TCATTAATCAAGAA-GAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGT-GTTCCGACCATAAACGATGCCGACTAGCGATCCGGCGGCGTTTTTCCCATGACCCGCC-AGCAGCTTCCGGGAAACCAAAGTCTTTGGG--CCGGGGGGAGTATGGTTGCAAAGCT-AAACTTAA------------------------------------------------------AACACGGG-AACCT--CCCGGCC-GGACACGGAAAGG-----------------------------------------TTGCATGGCT-TT-TT-GTTGGTGGAGCTTTTTGTCT-GTTTATTCCGATAACGA-TGAGACTTC-TCCATGCT-ACTAGTTACGCGACCCCCA-GC-GTCGG--T-------TTT-T-A-AGGGACAAGTGGCGTT-AGCC-CACGAGAT-GAGCAATAACA-GTCTGT-ATGCCCT-A-ATGTC-----CTGCACGCGCGCT-CACTGA-ACGGATCAGCGTGTGTCTACCCTTCGC-GACAGGT--GGGTTACCCGCT-AACCCC-TT--TGATAGGGAAAGGGGATTGCAATTATTTCCCAT-AACGAGGAATTCCCAGTAAGTGCGGGACATAAGCT-GCGTTGATT--G-CCC--C--TTTGTACACAC---TTTTCGCT-CTACCGATT-GAT-GTTTAGT-AGGT-CTCGGAT-GGCCCC---GGGGT-GG-CGACGGCCCT-----AGCGCCGAGAAGACGATCAAAC---ACTATC----------------------------------------------------------', '-----------------------------------TCAA-GA---AGCCATGCACGTGTAAGTACACACGGCCGGTACAGTGAAACTGCGAATGGC----TAAATCAGTTAT-G--------ATCGCTC-ATCCGT----ACTTGGATAACTGTGGT---TCT-GAGCT-AT-C-TGCCGACGAGCGCT-ACCCCC-----------CGG-ATGCGTGC-TTTATC-GACCAAAACCAATGGGCT-GCC---C-----------------------------------------------------------------------------------------------GC---GGTGACTCTAGATAACCTCGGGC-GATCGCACGTC-CGCGTGACGGCGACGATACATTCGGATGTCTGCCCTATC-ACTTTCGATGGTACTTTCT--GCCTACCATGGTGAC-ACGGGTAACGGGGAATCAGGG--CGA----GGAGA-GGAGCC-GAGAAACGGCT-CCACA--CAAG-A-GGCAGCA-GCGC----ATTACCGACTCC-GACT-GGGGA---A---A--AAAAATAACAATACAGGACTCT-TCGAGGC--GGG-ATTGGAATGAGTACACTTT-AA-CCTTTAACGAGGAT-CA--GGAGGGCAA-------GCC-GCAGC-GCGG---TTCCAGCTCCAATA--GTATATT-AAGTTGC-GCAGTT--AAAGCTCGTAGTT-GATCTTG----------GGATCGAGCTGG--GTC-GC-GCGAGGCGACG--CCGC--GTCCCA-GCCCCC-G--TCTCGGCGCCTCCC-GATGCTCTTGACT-AGTGTCCCG--GGGGCCCGAAG-G--TACTTTGAAAAAATT-GAGTGTTCAAAGCAGGCC-G--TCGCCTGAATACTTCAG-T-GGAATAATGGAATAGGACTCCGGTTC--TTTTGTT-GTTTTCGGAACTGGGGCCATGATTAAGAGGG--------------TCGTATTGTGCCGCTAGAGGT-AAATTCTTGGACCGGCGCTAGACGAACC-AAGCGAAAGCATTTGCC-AGAAT-TTTTCATT-ATC-A-AA-GAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGT-GTTCCGACCAT-AACGATGCCGACTTGCGATCCGGCG---TTTTTCCCATGACCCGC---GCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGG---GTATGGTTGCAAAGCT-AAACTTAA------------------------------------------------------AACACGGGT-ACCT--CCCGGCC-GGACACGGAAAGG----------------------------------------TTT--A---CTTTT-TT-GTT--T-GA----TTTGTCTTGTTTATTCCGATAAC---T-A-TC-TC-TC-ATGCTTACTAGTTACGCGACCCCCA-GC-GTCGG--T-C-----TTT-TTA-ATGG-CAAGTGGACTTCAGCCACACGAGATCGAGCAATAACATGTCTGT-ATGCCCTTAGATGTCC----CTGC-CGCGCGCT-CACTGA-ACGGATCAGCGTGTGTCTACCCTTCGC-GACAGGT--GGGTTACCCGCT-AACCCCGTT--TGATAGGGATAGGGGATTGC-ATTATTTCCCAT-AACGAGGTATTCCCAGTAAGTGCGGGTCATAAGCT-GCGTTGATT--GTCCCC-CCC--TGTACACAC--CC--TCGCT-CTACC-ATTGGATGGTTTAGTGAGGT-CTCGGAT-GGCCCCC--GGGGT-GG-CGACGGCC-T------GCGCCGAGAAGACGATCAAAC---ACTATC----------------------------------------------------------', 'TACCTGGTTGATCCTGCCAGTAGCATATGCTTGTCTCAAAGATTAAGCCATGCATGTCTAAGTACAAACGGTGCGTACAGTGAAACTGCGAATGGCTCATTAAATCAGTTATGGTTCCTTTGATCGCTCCAAC-GT---TACTCGGATAACTGTGGTAATTCTAGAGCTAATACATGCCGACGAGCGCTGACCTTC-----------GGGGATGCGTGCATTTATCAGACCAAAACCAATCCGGGTCCGCCCGGCC--------------------------------------------------------------------------------------------GCTTTGGTGACTCTAGATAACCTCGGGCCGATCGCACGTC-CTCGTGGCGGCGACGATTCCTTCGAATGTCTGCCCTATCAACTTTCGATGGTACTTTCTGTGCCTACCATGGTGACCACGGGTAACGGGGAATCAGGGTTCGATTCCGGAGAGGGAGCCTGAGAAACGGCTACCACATCCAAGGAAGGCAGCAGGCGCGCAAATTACCCACTCCCGACGCGGGGAGGTAGTGACGAAAAATAACAATACAGGACTCTTTCGAGGCCCTGTAATTGGAATGAGTACACTTTAAATCCTTTAACGAGGATCTATTGGAGGGCAAGTCTGGTGCCAGCAGCCGCGGTAATTCCAGCTCCAGTAGCGTATATTAAAGTTGCTGCAGTTAAAAAGCTCGTAGTTGGATCTTG----------GGATCGAGCTGGCGGTCCGCCGCGAGGCGAGCTACCGCCTGTCCCA-GCCCCT-GCCTCTTGGCGCTCCCTTGATGCTCTTAACTGAGTGTCCTG--GGGGTCCGAAGCGTTTACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCCGG--TCGCTTGGATACTTCAGCTAGGAATAATGGAATAGGACTCCGGTTCTATTTTGTTGGTTTTCGGAACTGGGGCCATGATTAAGAGGGACGGCCGGGGGCATTCGTATTGTGCCGCTAGAGGTGAAATTCTTGGACCGGCGCAAGACGGACAAAAGCGAAAGCATTTGCCAAGAATGTTTTCATTAATCAAGAACGAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCAACTACCGATCCGGCGGCGTTATTTCCATGACCCGCCGGGCAGGTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCTGAAACTTAAAGGAATTGACGGAAGGGCACCACCAGGAGTGGAGCCTGCGGCTTAATTTGACTCAACACGGGAAACCTCACCCGGCCCGGACACGGAAAGGATTGACAGATTGATAGCTCTTTCTCGATTCTGTGGGTGGTGGTGCATGGCCGTTCTTAGTTGGTGGAGCGATTTGTCTGGTTAATTCCGATAACGAACGAGACTCC-TCCATGCTAAATAGTTACGCGACCCCGA-GTGGTCGGCGTCC---AACTTCTTAGAGGGACAAGTGACGTTTAGCCACACGAGATTGAGCAATAACAGGTCTGTGATGCCCTTAGATGTCCGGGGCTGCACGCGCGCTACACTGA-ATGGATCAGCGTGTGTCTACCCTACACCGACAGGTGCGGGTAACCCGTTGAACCCCATTCGTGATAGGGATCGGGGATTGCAATTATTTCCCGTGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGCTCGCGTTGATTAAGTCCCTGCCCTTTGTACACACCGCCCGTCGCTACTACCGATTGGATGGTTTAGTGAGGTCCTCGGATCGGACCCGCCGGGGTCGT-CCGCGGCCCTGGCGGAGCGCTGAGAAGACGATCAAACTTGACTATCTAGAGGAAGTAAAAGTCGT---------------------------------------', 'TACCTGGTTGATCCTGCCAGTAGCATATGCTTGTCTCAAAGATTAAGCCATGCATGTCTAAGTACGCACGGCCGGTACAGTGAAACTGCGAATGGCTCATTAAATCAGTTATGGTTCCTTTGGTCGCTCGCTCCTCTCCTACTTGGATAACTGTGGTAATTCTAGAGCTAATACATGCCGACGGGCGCTGACCCCCCTTCCCGGGG-GGGGATGCGTGCATTTATCAGATCAAAACCAACCCGGTGAGCTCCCTCCCGGCTCCGGCCGGGGGTCGGGCGCCGGCG---------------------------------------------------------------GCTT-GGTGACTCTAGATAACCTCGGGCCGATCGCACGCCCCCCGTGGCGGCGACGACCCATTCGAACGTCTGCCCTATCAACTTTCGATGGTAGTCGCCGTGCCTACCATGGTGACCACGGGTGACGGGGAATCAGGGTTCGATTCCGGAGAGGGAGCCTGAGAAACGGCTACCACATCCAAGGAAGGCAGCAGGCGCGCAAATTACCCACTCCCGACCCGGGGAGGTAGTGACGAAAAATAACAATACAGGACTCTTTCGAGGCCCTGTAATTGGAATGAGTCCACTTTAAATCCTTTAACGAGGATCCATTGGAGGGCAAGTCTGGTGCCAGCAGCCGCGGTAATTCCAGCTCCAATAGCGTATATTAAAGTTGCTGCAGTTAAAAAGCTCGTAGTTGGATCTTG----------GGAGCGGGCGGGCGGTCCGCCGCGAGGCGAGTCACCGCCCGTCCCC-GCCCCTTGCCTCTCGGCGCCCCCTCGATGCTCTTAGCTGAGTGTCCCG-CGGGGCCCGAAGCGTTTACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCCCGAGCCGCCTGGATACCGCAGCTAGGAATAATGGAATAGGACCGCGGTTCTATTTTGTTGGTTTTCGGAACTGAGGCCATGATTAAGAGGGACGGCCGGGGGCATTCGTATTGCGCCGCTAGAGGTGAAATTCTTGGACCGGCGCAAGACGGACCAGAGCGAAAGCATTTGCCAAGAATGTTTTCATTAATCAAGAACGAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACTGGCGATGCGGCGGCGTTATTCCCATGACCCGCCGGGCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCTGAAACTTAAAGGAATTGACGGAAGGGCACCACCAGGAGTGGGCCT-GCGGCTTAATTTGACTCAACACGGGAAACCTCACCCGGCCCGGACACGGACAGGATTGACAGATTGATAGCTCTTTCTCGATTCCGTGGGTGGTGGTGCATGGCCGTTCTTAGTTGGTGGAGCGATTTGTCTGGTTAATTCCGATAACGAACGAGACTCT-GGCATGCTAACTAGTTACGCGACCCCCGAGCGGTCGGCGTCCCCCAACTTCTTAGAGGGACAAGTGGCGTTCAGCCACCCGAGATTGAGCAATAACAGGTCTGTGATGCCCTTAGATGTCCGGGGCTGCACGCGCGCTACACTGA-CTGGCTCAGCGTGTGCCTACCCTGCGCCGGCAGGCGCGGGTAACCCGTTGAACCCCATTCGTGATGGGGATCGGGGATTGCAATTATTCCCCATGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGCTTGCGTTGATTAAGTCCCTGCCCTTTGTACACACCGCCCGTCGCTACTACCGATTGGATGGTTTAGTGAGGCCCTCGGATCGGCCCCGCCGGGGTCGGCCCACGGCCCTGGCGGAGCGCTGAGAAGACGGTCGAACTTGACTATCTAGAGGAAGTAAAAGTCGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTA', '--CCT-GTT-ATCCTGCCAGTAGCT---GCTTGTCTC-AAGATTAAGCCATGCACGTGTGAGT-CGCACGGCCGGTAC-GTGAAACTGCGAATGGC---TTAAATCAGTTAT-G---CTT--ATCGCTCCATCC------AC-----------------------------------------------------------------AGGGATGCGTGCATTTAT-AGACCAAAACCAAT-GGG-----------------GGGTTTG--GG-G--GGGGGGGGGGGGTCGCGT-AG-C-------CC---G-CC--TCCTCCCG-GCCC-C-GTCCC-TCCC----CGCCT-GGT-ACTCTAGATAACCTCGGG---ATCGCACGTC-CCCGTGACGGCGACGATACATTCGGATGTCTGCCCTATCAACTTTCGATGGT-CTTTCTGCGCCTACCATGGTGACCACGGGTAACGGGGAATCAGGGTTCGATTCCGGAGAGGGAGCCTGAGAAACGGCT-CCACATCCAAGGA-GGCAGCAGGCGCGC--ATTACCCACTCC-GAC--GGGGAG-TAGTGAC-AAAAATAACAATACAGGACTCTTTCGAGGCCCTGTAATTGGAATGAGTACACTTT-AA-CCTTTAACGAGGATCC-TTGGAGGGCCAGTCTGGTGCCAGCAGCCGCGG---TTCCAGCTCCAATA--GTATATT-AAGTTGCTGCAGTT--AAAGCTCGTAGTT-GATCTTG----------GGATCGAGCTGG-GGTC-GCCGTGAGGCGA-G--CCGCC-GTCCCA-GCCCC--G--TCTCGGCGCCTCCCCGATGCTCTTGACTGAGTGTCCCG--GGGGCCCGAAGCG--TACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCC------GCCTGAATACTTCAGCTAGGAATAATGGAATAGGACTCCGGTTCT-TTTTGTT-GTTTTCGGAACTGGGGCCATGATTAAGAGGG--------------TCGTATTGTGCCGCTAGAGGTGAAATTCTTGGACCGGCGCAAGACGAACCAAAGCGAAAGCATTTGCCAAGAAT-TTTTCATTAATCAAGAA-GAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACTAGCGATCCGGCGGCGTTTTTCCCATGACCCGCCGG-CAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCT-AAACTTAA------------------------------------------------------AACACGGG-AACCT--CCCGGCCCGGACACGGAAAGGA----------------------------------------TTGC-TGGCTTTT-TT-GTTGGTGGAG---TTTGTCT-GTTTATTCCGATAACGA--GAGACT-C-TCCGTGCT-ACT-GTTACGCGACCCC------GTCCGCGTCC-----CTT-TTAG-GGGACAAGT-G-GCTTAGCCACGCGAGATCGAGCAATAACA-GTCTGT-ATGCCCTTAGATGTCCG---CTGCACGCGCGCT-CACTGA-ACGGACCAGCGTGTGTCTACCCTTCGC-GACAGGT--GGG--ACCCGCT-AACCCC----GTGA-AGGGA--GGGGATTGCAATTATTTCCCATGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGCT-GCGTTGATT--GTCCCT-CCCTTTGTAC-CAC----TTTCGCTACTCCCGAT-GGAT-GTTTAGTGAGGT-C-CGGAT-GGCCCCC--GGGGTCGC-C-ACGGCCCT-----CGCGCCGAGAAGACGATCAAAC---ACTATC----------------------------------------------------------', 'TACCTGGTTGATCCTGCCAGTAGCATATGCTTGTCTCAAAGATTAAGCCATGCATGTCTAAGTACGCACGGCCGGTACAGTGAAACTGCGAATGGCTCATTAAATCAGTTATGGTTCCTTTGGTCGCTCGCTCCTCTCCTACTTGGATAACTGTGGTAATTCTAGAGCTAATACATGCCGACGG-CGCTGACTCCC-TTTGTG----TGGGATGCGTGCATTTATCAGATCAAAACCAACCCGGTCAGCCTCCCCGCCGGCCGGGGGGGTGGGGCGGCG---------------------------------------------------------------------GCTTTGGTGACTCTAGATAACCTCGGGCCGATCGCA-GCCCTCCGTGGCGGCGACGACCCATTCGAACGTCTGCCCTATCAACTTTCGATGGTAGTCGCCGTGCCTACCATGGTGACCACGGGTGACGGGGAATCAGGGTTCGATTCCGGAGAGGGAGCCTGAGAAACGGCTACCACATCCAAGGAAGGCAGCAGGCGCGCAAATTACCCACTCCCGACCCGGGGAGGTAGTGACGAAAAATAACAATACAGGACTCTTTCGAGGCCCTGTAATTGGAATGAGTCCACTTTAAATCCTTTAACGAGGATCCATTGGAGGGCAAGTCTGGTCGCAGCAGCCGCGGTAATTCCAGCTCCAATAGCGTATATTAAAGTTGCTGCAGTTAAAAAGCTCGTAGTTGGATCTTGTGGAGGGTGCGTAGCGGGCG----GTCCGCCGCGAGGCGAGCCACCGCCCGTCCCC-GCCCCTTGCCTCTCGGCGCCCCCTCGATGCTCTTAGCTGAGTGTCCCG-CGGGGCCCGAAGCGTTTACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCCCGAGCCGCCTGGATACCGCAGCTAGGAATAATGGAATAGGACCGCGGTTCTATTTTGTTGGTTTTCGGAACTGAGGCCATGATTAAGAGGGACGGCCGGGGGCATTCGTATTGCGCCGCTAGAGGTGAAATTCTTGGACCGGCGCAAGACGGACCAGAGCGAAAGCATTTGCCAAGAATGTTTTCATTAATCAAGAACGAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACTGGCGATGCGGCGGCGTTATTCCCATGACCCGCCGGGCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCTGAAACTTAAAGGAATTGACGGAAGGGCACCACCAGGAGTGGAGCCTGCGGCTTAATTTGACTCAACACGGGAAACCTCACCCGGCCCGGACACGGACAGGATTGACAGATTGATAGCTCTTTCTCGATTCTGTGGGTGGTGGTGCATGGCCGTTCTTAGTTGGTGGAGCGATTTGTCTGGTTAATTCCGATAACGAACGAGACTCT-GGCATGCTAACTAGTTACGCGACCCCCGAGCGGTCGGCGTCCCCCAACTTCTTAGAGGGACAAGTGGCGTTCAGCCACCCGAGATTGAGCAATAACAGGTCTGTGATGCCCTTAGATGTC-GGGGCTGCACGCGCGCTACACTGA-CTGGCTCAGCGTGTGCCTACCCTACGCCGGCAGGCGCGGGTAACCCGTTGAACCCCATTCGTGATGGGGATCGGGGATTGCAATTATTCCCCATGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGCTTGCGTTGATTAAGTCCCTGCCCTTTGTACACACCGCCCGTCGCTACTACCGATTGGATGGTTTAGTGAGGCCCTCGGATCGGCCC-GCCGGGGTCGGCCCACGGCCCTGGCGGAGCGCTGAGAAGACGGTCGAACTTGACTATCTAGAGGAAGTAAAAGTCGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTA', '-----GGTT-ATCCTGCCAG-AGCA---GCTTGTCTCAAAGATTAAGCCATGCACGTGTAAGTACGCACGGCCGGTACAGTGAAACTGCGAATGGCT--TTAAATCAGTTA------CTT--ATCGCTCCAT---T---TACTTGGATAACTGTGGT-ATTC--GAGCT-ATACATGCCGA-GAGCGCT-ACCTTCAC---------CGGGATG-GTGCATTTATCAGACC--AACCAATCGGG-GCCC-CCT-G----------------------------------------------------------------------------------------------CTTTGGT-ACTCTAGATAACCT-GGG-T-ATCGCA-GTC-CCCGTGACGGCG---------------------------------------------------------------------------GGGAA--AGGG---------GGAGAGGGAGCCTGAGAAACGGCT-CCACAT-CAAGG--GGCAGCAGGCGC-C--ATTACCCAC-CC-GAC-CGGGGA-----T-A--AAAAATAACAATACAGGACTCT--CGAGGCCCTG--ATTGGAATGAGTACACTTT-AA-CCTTTAACGAGGATCCATTGGA---C-AGTCT-GTGCC--CAGCCGCG----TTCCAGCTCCAA---CGTATATTAAAGTTGC-GCAGTT--AAAGCTCGTAGTT-GATCTTG----------GGAT-GAGCT----GTCCGCCGCGAGGCGA----CCGC--GTCCCA-GCCC------TCT-GGT-CCCCCCCGATGCTCT---CT-AGTGTCCCG--GG--TCCGAAGT-TTTACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCC-G--T-GCCT-AATACTTCAGCTAGGAATAATGGAATAGGACTCC-GTTCT-TTTTGTT-GTTTTCGGAACTGGGG--ATGATTAAGAGGGACG------------CGTATTGTGCCGCTAGAGGT-AAATTCTTGGACCGGCGCAAGACGAACCAAAGCGAAAGCATTTGCCAAGAAT-TTTTCATTAATCAAGAA-GAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGT-GTTCCGACCATAAACGATGCCGACTAGCGATCCGGCGGCGTTTTTCCCATGACCCGCCTAGCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCT-AAACTTAAAGGAATTG----------------------------------------------------GGAAACCT-ACCCGGCCCGGACACGG-AAGGA---ACAGATTGATAGCT-TTTCTCGATTCTGTGGGT--T-TTGC-TGGCT-TTCTTAGTTGGTGGAG--ATTTGTCT-GTT-ATTCCGAT-ACGA--GAGACT-C-TCCATGCT-AC-AGTTACGCGACCCCC--GC-GTCGGCGT-----T-CT---TAGAGGGAC-AGTGGCGTT-AGCCACACGAGATCGAGCAATAA---GTCTGTGATGCCCTTAGATGTCC----C-GC-CGCGCGCTAC-CTGA-ACGGATCAGCGTGTGTCTACCCTTCGCCGACAGGT-CGGG--ACCCGCT-AACCCCGTT-GTGATAGGGATTGGGGATTGCAATTATTTCCCATGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGCT-GCGTTGATT--GTCCC--C--TTTGTACACACC-----TCGCTACTACCGATTGGATGGTTTAGTGAGGT-CT-GGAT-GGCCCCC--GGGGT-GG-C-ACG-CC-T------GCGCCGAGAAGACGATCAAACT-GACTATC----------------------------------------------------------', 'TACCTGGTTGATCCTGCCAGTAGCATATGCTTGTCTCAAAGATTAAGCCATGCATGTCTAAGTACGCACGGCCGGTACAGTGAAACTGCGAATGGCTCATTAAATCAGTTATGGTTCCTTTGGTCGCTCGCTCCTCTCCTACTTGGATAACTGTGGTAATTCTAGAGCTAATACATGCCGACGGGCGCTGACCCCCCTTCCCGTGGGGGGAACGCGTGCATTTATCAGATCAAAACCAACCCGGTCAGCCCCCTCCCGGCTCCGGCCGGGGGTCGGGCGCCCGGCG--------------------------------------------------------------GCTTTGGTGACTCTAGATAACCTCGGGCCGATCGCACGT-CCCCGTGGCGGCGACGACCCATTCGAACGTCTGCCCTATCAACTTTCGATGGTAGTCGCCGTGCCTACCATGGTGACCACGGGTGACGGGGAATCAGGGTTCGATTCCGGAGAGGGAGCCTGAGAAACGGCTACCACATCCAAGGAAGGCAGCAGGCGCGCAAATTACCCACTCCCGACCCGGGGAGGTAGTGACGAAAAATAACAATACAGGACTCTTTCGAGGCCCTGTAATTGGAATGAGTCCACTTTAAATCCTTTAACGAGGATCCATTGGAGGGCAAGTCTGGTGCCAGCAGCCGCGGTAATTCCAGCTCCAATAGCGTATATTAAAGTTGCTGCAGTTAAAAAGCTCGTAGTTGGATCTTG----------GGAGCGGGCGGGCGGTCCGCCGCGAGGCGGCTCAGCGCCCGTCCCCAGCCCCT-GCCTCTCGGCGCCCCCTCGATGCTCTTAGCTGAGTGTCCCG-CGGGGCCCGAAGCGTTTACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCCCGAGCCGCCTGGATACCGCAGCTAGGAATAATGGAATAGGACCGCGGTTCTATTTTGTTGGTTTTCGGAACTGAGGCCATGATTAAGAGGGACGGCCGGGGGCATTCGTATTGCGCCGCTAGAGGTGAAATTCTTGGACCGGCGCAAGACGAACCAGAGCGAAAGCATTTGCCAAGAATGTTTTCATTAATCAAGAACGAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACTGGCGATGCGGCGGCGTTATTCCCATGACCCGCCGGGCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCTGAAACTTAAAGGAATTGACGGAAGGGCACCACCAGGAGTGGAGCCTGCGGCTTAATTTGACTCAACACGGGAAACCTCACCCGGCCCGGACACGGACAGGATTGACAGGTTGATAGCTCTTTCTCGATTCCGTGGGTGGTGGTGCATGGCCGTTCTTAGTTGGTGGAGCGATTTGTCTGGTTAATTCCGATAACGAACGAGACTCTCGGCATGCTAACTAGTTACGCGACCCCCGAGCGGTCGGCGTCCCCCAACTTCTTAGAGGGACAAGTGGCGTTCAGCCACC-GAGATTGAGCAATAACAGGTCTGTGATGCCCTTAGATGTCCGGGGCTGCACGCGCGCTACACTGAACTGGTTCAGCGTGTGCCTACCCTACGCCGGCAGGCGCGGGTAACCCGTTGAACCCCATTCGTGATGGGGATCGGGGATTGCAATTATTCCCCATGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGCTTGCGTTGATTAAGTCCCTGCCCTTTGTACACACCGCCCGTCGCTACTACCGATTGGATGGTTTAGTGAGGCCCTCGGATCGGCCCCGCCGGGGTCGGCCCACGGCCTTGGCGGAGGCCTGAGAAGACGGTCGAACTTGACTATCTAGAGGAAGTAAAAGTCGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTA', '------GTT-AT--TGC-AG--G-----GCTTGTCTC-----TT-AGCCATGCACGTGTAAGTACACACGGCCGGTACAGTGAAACTGCGAATGGC---TTAAATCAGTTAT-G---CTT--ATCGCTC-ATC--T----ACTTGGATAA---------------------------------------------------------AGG-ATGCGTGCATTTATCAGACCAAAACCAATCGGGTGGC-C-CCCCTCCC--CC-------------------------------------------------------------------------------------GCT--GGT-ACTCTAGATAACCTCGGGCCGATCGCA--TC-CCCGTGACGGCGACGATA--TTTGGATGTCTGCCCTAT--ACTTTCGAT-GT-CTTTCTGTGCCTACCTTGGTGACCACGGGTT--GGG--AT--GG-TT-G-TT-CGGAGA--G-GCCT-AG-AACGGCT-CCACAT-CAAGGT-GGCAGCAGGCGC----ATTACCCACTCC-GACTCGGGGA---AGTGA--AAAAATAACAATACAGGACTCTTTCGAGGCCCTGT-ATTGGAATGAGTACACTTT-AA-CCTTTAACGAGGATCTATTGGAGGGCAAGTC--------GCAGCCGC-G--ATTCCAGCTCCAATA--GTATATT-AAGTTGCT-C-GTT--AAAGCT-GTAGTT-GATCTTG----------GGAT-GAGCT----GTCCGCCGCGAGGCGACG--CCGC--GTCCC--GCCCCC----TCT----GCCTCCC--ATGCTCTTGACT-AGTGTCCCG--GG---CCGAAG----TACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCC-G--TCGCCTGAATACTTCAGCTAGGAATAATGGAATAGGACTCCGGTTCT-TTTTGTT-GTTTTCGGAACTGGGG--ATGATTAAGAGGGACGG-----------CGTATTGTGCCGCTAGAGGT-AAATTCTT-GACCGGCGCAAGACGAACCAAAGCGAAAGCATTTGCCAAGAAT-TTTTCATTAATCAAGAA-GAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGT-GTTCCGACCATAAACGATGCCGACTAGCGATCCGGCGGCGTTTTTCCCATGACCCGCC-AGCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCTGAAACTTAAAGG---------------------------------------------------------GG-AACCT--CCC--CCCGGACACGGAAAGGA---ACAGATTGATAGC------------------------TTG--TGGCTTTT-TT-GTTGGTGGAG---TTTGTCT-GTTTATTCCGATAACGAA-GAGACT-C-TC-AT-CT-ACT-GTTACGCGAACCC---GC-GT-GG-GT-------CT--TTAGAGGGACAAGTGGCGTTCAGCCACACGAGA--GAGCAATAA-A-GTCTGT-ATGCCCTTAGATGTCC----CTGCACGCGCGCT-CACT-A-ACGGATCAGCGTGTGTCTACCCTTCGC-GACAGG---GGG--ACCCGCT-AA-CCCGTT-GTGA-AGGGATTGGGGATTGCAATTATTTCCCATGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGC--GC-TTGATT--GTCCCT-CCCTTTGTAC-CAC---TTTTCGCT-CTACCGATTGGATGGTTTAGTGAGGTCCTCGGAT-GGCCCCC--GGGGT-GG-C-ACGGCCCT----GAGC-CCGAGAAGACGATCAAAC--G--TATC----------------------------------------------------------', '----------------------------GC--GTCTCAAAGATTAAGCCATGCATGTCTAAGTACACACGGGCGTTA-AGTGAAACTGCGAATGGCT---TAAATCAGTTATGGT--CT---GTCGCTCCCCC--T---TCCTTGGATAACTGTGGT---TCTAGAGCTAATACATGCCAACGAGCGCTGACCTCC-----------GGGGATGCGTGCATTTATCAGACCAAAACCAACGGGCTCGCCC--CC----------------------------------------------------------------------------------------------GCT-TGGT-ACTCTAGATAACCTCGGGCCGATCGCA-GCC-C-CGTGGCGGCGACGACGCATTCGAATGTCT-CCCTATCAACTTTCGATGGTACTTTCTGCGCCTACCATGGTGACC-CGGGTA--GGGGAATCAGGGTTCGATT--GG-GAGGGAGCCTGAGAA-CGGCT-CCACATCCAAGG--GGCAGCAGGCGC----ATTACC-ACTCCCGAC--GGGGAG-TAGTGA--AAAAATAACAATACAGGACTCTTTCGAGGCCCTGT-ATTGGAATGAGTACACTTTAAATCCTTTAACGAGGA-CCATTGGAGGGCAAG------------------------------------------------------------------------------------------------------------------------------G-CCGCC-GTCCCA-GCCCCC-G--TCTCGGCGCTCCCCCGATGCTCTTAGCTGAGTGTCC-G--GGG-TCCGAAG----TACTTTGAAAAAATTAGAGTGTTCAAAGCAGGC-GC--TCGCCTGAATACTCCAGCT-GGAATAAT-GAATAGGACTCCGGTTCT-TTTTGTT-GTTTTCGGAACTGGGGCCATGATTAAGAGGG-CGC--GGG----TTCGTATTGTGCCGCTAGAGGTGAAATTCTTGGACCGGCGCAAGACGAACCAGAGCGAAAGCATTTGCCAAGAAT-TTTTCATTAATCAAGAACGAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACTAGCGATCCGGCGGCGTTATTCC--T-A-CCGCC-----GCTTCCGGGAAACCAAAGTG-TTGGGT-----------------------------------------------------------------------------------------AACACGGGAAACCTC-CCCGGCCCGGACACGGAAAGGA--GACAGATCGATAGCTCTTTCTCGATTC-GT-GGT-----TGCATGGC---TCTTAGTTGGTGGAGC-ATTTGTCT-GTT-ATTCCGATAACGA--GAGACTCT-GGCATGCT-ACTAGTTATGCGACCCCCGAGCGGTCGG-GTCC---AA--T-TTAGAGGGACAAGTGGCGTT-AGCCACCCGAGATT-AGCAATAACA-GTCTGTGATGCCCTTAGATGTCCGG-GCTGCA-GCGCGCTACACTGA-CTGGCT-AGCGTGTGTCTACCCTACGCCGACAGGTGCGGGTAACC-GTTGAACCCCATTCGTGA-GGGGATCGGGGATTGCAATTATTCCC-AT-AACGAGGAATTCCCAGTAAGTGCGGGTCATAAGCTCGCGTTGATT--GTCCCTGCCCTTTGTACACACCTC---TCGCTACTACCGATTGGATGGTTTAGTGAGGTCCTCGGAT-GGCCCCGCCGGGGTCG--CCTCGGCCC------AGCGCCGAGAAGACGGTCGAACT--ACTATCTAGAGGAAG-------------------------------------------------', '--CCTGGTTGATCCTGCCAGTAGCA---GCTTGTCTCAAAGATTAAGCCATGCACGTGTAAGTACACACGGCCGGTACAGTGAAACTGCGAATGGCT-A-TAAATCAGTTATGGT--CTT--ATCGCT---CC-GT---TACTTGGATAACTGTGGT-ATTCT-GAGCTAATACATGCCGACGAGCGCTGACCTC------------CGGGATGCGTGCATTTATCAGACCAAGACCAATGGGC-CGCC----CC---------------------------------------------------------------------------------------------GCT--GGT-ACTCTAGATAACCTCGGGCC-ATCGCACGTCCCCCGTGACGGCGACGATGCATTCGGATGTCTGCCCTATCAACTTTCGATGGTACTTTCTGTGCCTACCATGGTGACCACGGGTAACGGGGAATCAGG-TTC------GGAGAGGGA-CCTGAGAAACGGCT-C-A-A-CCAAGG--GGCAGCAGG-GC----ATTACCCACTCCCGAC-TGGGGA--TAGT-A--AAAAATAACAATACAGGACTCTTTCGAGGCCCTGT-ATTGGAATGAGTACACT-T-AATCCTTTAACGAGGATCCATTGGAGGGCAAGTCTGGTGCTAGCAGC---GG---TT-CAGCTCCAA-AGCGTATATTAAAGTTGCTGCAGTT--AAAGCTCGTAG---GATCTTG----------GGATCGAGCT----GTCCGCCGCGAGGCGAG-CACCGC--GTCCCA-GCCCCC-G--TCTCGGCGCCCCCTCGATGCTCTTGACTGAGTGTCCCG--GG---CCGAA-----TACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCCGG--TCGCCTGAATACTGCAGCTAGGAATAATGGAATAGGACTCCGGTTCT-TTTTGTT-GTTTTCGGAACTGGGGCCATGATTAAGAGGGACG-CCGG-----TTCGTATTGTGCCGCTAGAGGTGAAATTCTTGGACCGGCGCAAGACGGACTAAAGCGAAAGCATTTGCCAAGAAT-TTTTCATTAATCAAGAA-GAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGT-GTTCCGACCATAAACGATGCCGACT-GC-ATCCGGCGGC-TTATTCCC-T-ACCCGCC--GCAGCTTCCGGGAAACCAAAGTC--TGGG---CGGGGGGAG-AGGGT---------------------------------------------------------------------------------AACCTCACCCGGCCCGGACACGGAAAG-----ACAGATTGATAGCTCTTTCTCGATTCTGTGGGT-----TGCATGGC----CTTAGTTGGTGGAG------GTCTGGTTAATTCCGATAACGAA-GAGACTCC-CACATGCTAACTAGTTACGCGACCCCCA-GT-GTCGGCGTCC---AA-T--TTAGAGGGA-AAGTGGCGTTCAGCCACACGAGAT-GAGCAATAA-A-GTCTGT-ATGCCCTTAGATGT-------TGCA-GCGCGCTACACTGA-ACGGATCAGCGTGTGTCTACCCTTCGCCGACAGG---GGGTAACCCGCT-AACCCCGTTCGTGATAGGGATTGGGGATTGCAATTATTTCCCAT-AACGAGGAATTCCCAGTAAGT--GGGTCATAAGCT-GTGTTGATT--GTCCCT-CC-TTTGTAC-CAC------TCGCTACTACCGATTGGATGGTTTAGTGAG-TCCTCGGAT--GCCCC-C-GGGGT-GG-CG-CGGCC----------GCCGAG-AGACGATCAAACT--ACTA------------------------------------------------------------', '--CCTGGTTGATCCTGCCAGTAGCATA-GCTTGTCTCAAAGATTAAGCCATGCATGTCTAAGTACACACGGCCGGTACAGTGAAACTGCGAATGGC---TTAAATCAGTTATGGT--CTT--GTCGCTCC-ACCCT---TACTTGGATAACTGTGGT---TCT-GAGCT-AT-CATGCCGACGAGCGCTGACCTCC-----------GGG-ATGCGTGCATTTATCAGACCAAAACCAACGGGCTCGCCCGGCC----------------------------------------------------------------------------------------------GCT-TGGTGACTCTAGATAACCTCGGGC-GATCGCA-GCCCCCCGTGGCGGCGACGATGCATTCGAATGTCT-CCCTATCAACTTTCGATGGTACTTCCTGTGCCTACCATGGTGACCACGGGTAACGGGGAATCAGGGTTCGATT--GG-GAGGGA-CCTGAGAA-CGGCT-CCACATCCAAGGA-GGCAGCA-G-GCG---ATTACCCACTCCCGAC--GGGGAG-TAGTGA--AAAAATAACAATACAGGACTCTTTCGAGGCCCTGT-ATTGGAATGAGTACACTTTAAA-CCTTTAACGAGGA-CCATTGGAGGGCAAG-----------------------TTCCAGCTCCAATA--GTATATT-AAGTTGCT-C-G----AAAGCTCGTAG----ATCTTG----------GGATCGAGC-----GTCCGCCGCGAGGCGA-CG-CCGCC-GTCCCA-GCCCCC-G--TCTCGGCGCTCCCTTGATGCTCTT-ACT-AGTGTCCTG--GG-GTCCGAA-----TACTTTGAAAAAATTAGAGTGTTCAAAGCAGGC--G--TCGCCGGAATACTCCAGCTAGGAATAA-GGAATAGGACTCCGGTTCT-TTTTGTT-GTTTTCGGAACTGGGG--ATGATTAAGAGGAACGC-C-------TTCGTATTGTGCCGCTAGAGGTGAAATTCTTGGACCGGCGCAAGACGGACCAAAGCGAAAGCATTTGCCAAGAATGTTTTCATTAATCAAGAACGAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACTAGCGATCCGGCGGCGTTATTCCCA-GA-CCGC----CAGCTTACGGGAAACCAAAGTCTTTGGGT-CCGGGGGGAG-ATGG-------------------------------------------------------------------------AA-ACGGG--ACC---CCCGGCC-GGACACGGAAAGGA---ACAGATTGATAGCTCTTTCTCGATT-TGTGGG------TGCATGGC----CTTAGTTGGTGGAGC-ATTTGTCTGGTT-ATTCCGATAACGA-CGAGACT-T-GGCATGCTAAC-AGTTATGCGACCCC-GAGCGGTCGG---CC---AA----TTAGAGGGACAAGT-GCGTTTAGCCACCCGAGATT-AGCAATAACA-GTCTGT-ATGCCCTTA-ATGTCC----CTGCACGCGCGCT-CACTGA-CTGGCT-AGCGT-TGTCTACCCTACGCCGACAGGTGCGGG--ACC-GTTGAACCCCATTCGTGATGGG-ATCGGGGATTGCAATTATTCCC-AT-AACGA-GAATTCCCAGTAAGTGCGGGTCATAAGCT-G--TTGATT--GTCCCT-C--TTTGTACACACC-----TCGCTACTACCGATTGGATGGTTTAGTGAGGTCCTCGGATCGGCCCTGCCGGGGTCGG-TC-CGGCCCT-GT-GAGCGCCGAGAAGACGGTCGAAC---ACTATCTAGAGGAAG-------------------------------------------------', '--CCTGGTTGATCCTGCCAGTAGCAT--GCTTGTCTCAAAGATTAAGCCATGCATGTCTAAGTACACACGGGCGGTACAGTGAAACTGCGAATGGC----TAAATCAGTTATGGT--CTT--GTCGCTCCTCTCCCGC-TCCTTGGATAACTGTGGT---TCTAGAGCTAAT-CATGCCGACGAGCGCCGACCTCC-----------GGGGACGCGTGCATTTATCAGACCAAAACCAACGG----GCCC---A----------------------------------------------------------------------------------------------GCT-TGGTGACTCTAGATAACCTCGAGCCGATCGCA-GC-CCCCGCGGCGGCGACGACCCATTCGAATG----CCCTATCAACTT-CGATGGTACTGTCTGTGCCTACCATGGTGACCACGGGTGACGGG-AATCAGG--TCGAT-CCGG-GAG-GAGCCTGAGAA-CGGCT-CCACATCCAAGG--GGCAGCAGGCGCG---ATTACCCACTCCCGACCCGGGGA--TAGT-A--AAAAATAACAATACAGGACTCTTTCGAGGCCCTG--ATTGGAATGAGCGCACTTTAAATCCTTGAGCGAGGA-CCATTGGAGGGC--G-----TGCC-GCAGC-GCGG--ATTCCAGCTCCAATAGCGTATCTTAAAGTTGCTGCAGTT--AAAGCTCGTAG---GATCTTG----------GGATCGAGCT----GTCCGCCGCGAGGCGAGCCACCGCCTGTCCCA-GCCCCC-G--TCTCGGCGCCCCCTCGATGCTCTTAGCTGAGTGTCCGC--GGGGCC-GAAGCGTTTACTTTGAGAAAATTAGAGTGTTCAAAGCAGGCCG---CCGCCGG-ATACTGCAGCTAGGAATAATGGAATAGGACTCCGGTTCT-TTTTGTTGGTTTTCGGAAACGGGGCCATGATTAAGAGGGACGC-CGGG----TTCGTATTGTGCCGCTAGAGGT-AAATTCTTGGACCGGCGCAAGACGGCCTAGAGCGAAAGCATTTGCCAAGAATGTTTTCATTAATCAAGAA-GAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACT-GCGATCCGGCGGCGTTATTCCCATGACCCGC----CAGCTCCCGGGAAACCCAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCT-AAACTTAAAGGAATTGACGGAAGGGCACCACCAGGAGTGGCAG--G-GGCTTTATTT-----AACACGGGAAACCTCACCCG-CC-GGACACGGACAGGAT-GACAGATTGAGAGCTCTTTCTCGATTCCGTGGGT-G---TGCATGGC---TCTTAGTTGGTGGAGCGATTTGTCT-GTT-ATTCCGATAACGAACGAGACTCT-GGCATGCTAACTAGTTACGCGACCCCCGAGCGGTCGG--TCC---AA--TCTTAGAGGGACAAGTGGCGTTCAGCCACCCGAGATTGAGCAATAACA-GTCTGTGATGCCCTTAGATGTCCGG-GC-GCACGCGCGCTACACTGA-CTGGCT-AGCTTGTGCC--CCCT-CGCCGG-AGGCGCGGGTAACCCGTTGAACCCCATTCGTGATGGG-ATCGGGGATTGCAATTCTTCCCCGTGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGCT-GCGTTGATT--GTCCCT-C--TTTGTACACAC------TTGCTACTACCGATTGGATGGTTTAGTGAGGT-CTCGGATCGGCC--GC-GGGGT-G---C--GGC--TGC---AGTGTCGAGAAGACGGTCGAACT--ACTATCTAGAGGAAGC------------------------------------------------', '----TGGTTGATCCTGCCAGTAGCA---GCTTGTCTCAAAGATTAAGCCATGCACGTGTAAGTACACACGGCCGGTACAGTGAAACTGCGAATGGCT---TAAATCAGTTATGGT--CTT--ATCGCTCCATCC------ACTTGGATAACTGTGGT---TCT-GAGCT-AT-CATGCCGACGAGCGCTGACCTCC-----------CGG--TGCGTGCATTTATCAGACCA-AACCAATGG-CTCGCCC--CC----------------------------------------------------------------------------------------------GC---GGT-ACTCTAGATAACCTCGGGC-GATCGCA-GTCCCCCGTGACGGCGACGATGCATTCGGATGTCT-CCCTATCAACTTTCGATGGTACTTTCCG-GCCTACCATGGTGACCACGGGTAACGGGG-ATCAGG-TTCG-TT-CGG-GAGGGAGCCTGAG-A-CGGCT-CCACATCCAAGGA-GGCAGCAGGCG-----ATTACC-ACTCCCGAC--GGGGA----GT----AAAAATAACAATACAGGACTCTTTCGAGGCCCTGT-ATTGGAATGAGTACACTTT-AATCCTTTAACGAGGAT-CATTGGAGGGC-----------------------------------------------------------------------------------------------------------------------------------CCGCCTGTCCCA-GCCCCC-G--TCTCGG-GCCTCC-C-ATGCTCTTGACTGAGTGTCCCG--G--GTCCGAAG--TTTACTTTGAAAAAATTAGAGTGTTCAAAGCAGGCCGG--TCGCCTGAATACTTCAGCTAGGAATAATGGAATAGGACT-GGGTTCT-TTTTGT--GTTTTCGGAACTGGGG---T-ATTAAGAGGGACG----------TTCGTATTGTGCCGCTAGAGGT---ATTCTT-GACCGGCGC-AGACGAACCAAAGCGAAAGCATTTGCCAAGAAT-T--TCATTAATCAAGA--GAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGT-GTTCCGACCATAAACGATGCCGACT-GCGATCCGGC-GCGTT-TTC-AAT-ACCCGC---GCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGG--AGTATGGTTG-AA---TGAAACTTAAAGGAA---ACGGAAGGGCA-----AGGAG-GGCAG--GCGGCTTAAT--G----AACACGGGAAACCTCACCCGGCCCGGACACGGAAAGGA--GACAGATCGATAGCTCTTTCTCGATTCTGTGGGT----GTGCATGGCTGTTCTTAGTTGGTGGAGC-ATTTGTCTGGTTAATTCCGATAACGAATGAGAC--C-TCCATGCTAACTAGTTACGCGACCCCCA-GC-GTCGG-GTCC----A---CTTAGAGGGACAAGTGGCGTTTAGCCACACGAGAT-GAGCAATAACATGTCTGTTATGCCCTTA-ATGTCC----CTGCACGCGCGCT-CACTGA-A-GGATCAGCGTGTGTCTACCCTTCGCCGACAGGT-CGGGT-ACCCGCT-AACCCCGTTCGTGATAGGGATCGGGGATTGCAATTATTTCCCATGAACGAGGAATTCCC-GTAAGTGCGGGTCATAAGCT-GCGTTGATT--GTCCCTTCCCTTTGTACACAC--C-T-TCGCTACTACCGATTGGATGGTTTAGTGAGGTCCTCGGATCGGCCCCGCCGGGGTCGG-CG--GGCCC------AG-GCCGAG-AGACGATCAAACT--ACTATCT---GGAAG-------------------------------------------------', 'TACCTGGTTGATCCTGCCAGTAGCATATGCTTGTCTCAAAGATTAAGCCATGCACGTGTAAGTACGCACGGCCGGTACAGTGAAACTGCGAATGGCTCATTAAATCAGTTATGGTTCCTTTGATCGCTCCATCTGT---TACTTGGATAACTGTGGTAATTCTAGAGCTAATACATGCCGACGAGCGCTGACCCCC-----------AGGGATGCGTGCATTTATCAGACCAAAACCAATCCGGGGCCCCCGCGCCCCGGCC--------------------------------------------------------------------------------------GCTTTGGTGACTCTAGATAACCTCGGGCCGATCGCACGTC-CCCGTGACGGCGACGATACATTCGGATGTCTGCCCTATCAACTTTCGATGGTACTTTCTGCGCCTACCATGGTGACCACGGGTAACGGGGAATCAGGGTTCGATTCCGGAGAGGGAGCCTGAGAAACGGCTACCACATCCAAGGAAGGCAGCAGGCGCGCAAATTACCCACTCCCGACGCGGGGAGGTAGTGACGAAAAATAACAATACAGGACTCTTTCGAGGCCCTGTAATTGGAATGAGTACACTTTAAATCCTTTAACGAGGATCTATTGGAGGGCAAGTCTGGTGCCAGCAGCCGCGGTAATTCCAGCTCCAATAGCGTATATTAAAGTTGCTGCAGTTAAAAAGCTCGTAGTTGGATCTTG----------GGATCGAGCTGGCGGTCCGCCGCGAGGCGAGCTACCGCCTGTCCCA-GCCCCT-GCCTCTCGGCGCCTCCCCGATGCTCTTGACTGAGTGTCCCG--GGGGCCCGAAGCGTTTACTTTGAAAAAATTAGAGTGTTCCAAGCAGGCCGCG-TCGCCTGGATACTTCAGCTAGGAATAATGGAATAGGACTCCGGTTCTATTTTGTTGGTTTTCGGAACTGGGGCCATGATTAAGAGGGACGGCCGGGGGCATTCGTATTGTGCCGCTAGAGGTGAAATTCTTGGACCGGCGCAAGACGAACCAAAGCGAAAGCATTTGCCAAGAATGTTTTCATTAATCAAGAACGAAAGTCGGAGGTTCGAAGACGATCAGATACCGTCGTAGTTCCGACCATAAACGATGCCGACTAGCGATCCGGCGGCGTTATTCCCATGACCCGCCGAGCAGCTTCCGGGAAACCAAAGTCTTTGGGTTCCGGGGGGAGTATGGTTGCAAAGCTGAAACTTAAAGGAATTGACGGAAGGGCACCACCAGGAGTGGAGCCTGCGGCTTAATTTGACTCAACACGGGAAACCTCACCCGGCCCGGACACGGAAAGGATTGACAGATTGATAGCTCTTTCTCGATTCTGTGGGTGGTGGTGCATGGCCGTTCTTAGTTGGTGGAGCGATTTGTCTGGTTAATTCCGATAACGAACGAGACTCC-TCCATGCTAACTAGTTACGCGACCCCCG-GCGGTCGGCGTCC---AACTTCTTAGAGGGACAAGTGGCGTTCAGCCACACGAGATCGAGCAATAACAGGTCTGTGATGCCCTTAGATGTCCGGGGCTGCACGCGCGCTACACTGA-ACGGATCAGCGTGTGTCTACCCTGCGCCGACAGGTGCGGGTAACCCGCTGAACCCCGTTCGTGATAGGGATCGGGGATTGCAATTATTTCCCATGAACGAGGAATTCCCAGTAAGTGCGGGTCATAAGCTCGCGTTGATTAAGTCCCTGCCCTTTGTACACACCGCCCGTCGCTACTACCGATTGGATGGTTTAGTGAGGTCCTCGGATCGGCCCCGCCGGGGTCGG-CCACGGCCCTGGCGGAGCGCCGAGAAGACGATCAAACTTGACTATCTAGAGGAAGTAAAAGTCGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTA']\n",
      "Pre-computing DNABERT embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'-'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 241\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength of DNA sequences:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dnaseq))\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning training with DNA sequences:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dnaseq)\n\u001b[0;32m--> 241\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDNA_SEQUENCES\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdnaseq\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 140\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(DNA_SEQUENCES)\u001b[0m\n\u001b[1;32m    132\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(agent\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m    133\u001b[0m cfg \u001b[38;5;241m=\u001b[39m MockCfgNode({\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mENV\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREWARD\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCALE\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.0\u001b[39m},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     }\n\u001b[1;32m    139\u001b[0m })\n\u001b[0;32m--> 140\u001b[0m reward_env \u001b[38;5;241m=\u001b[39m \u001b[43mPhylogenticTreeEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDNA_SEQUENCES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Starting Reinforcement Learning Training ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n",
      "Cell \u001b[0;32mIn[20], line 55\u001b[0m, in \u001b[0;36mPhylogenticTreeEnv.__init__\u001b[0;34m(self, cfg, sequences, device)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevolution_model \u001b[38;5;241m=\u001b[39m EvolutionModelTorch(cfg\u001b[38;5;241m.\u001b[39mENV\u001b[38;5;241m.\u001b[39mEVOLUTION_MODEL)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchars_dict \u001b[38;5;241m=\u001b[39m CHARACTERS_MAPS[cfg\u001b[38;5;241m.\u001b[39mENV\u001b[38;5;241m.\u001b[39mSEQUENCE_TYPE]\n\u001b[0;32m---> 55\u001b[0m seq_arrays \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchars_dict[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m s]) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sequences])\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_arrays \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mtensor(seq_arrays, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[20], line 55\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevolution_model \u001b[38;5;241m=\u001b[39m EvolutionModelTorch(cfg\u001b[38;5;241m.\u001b[39mENV\u001b[38;5;241m.\u001b[39mEVOLUTION_MODEL)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchars_dict \u001b[38;5;241m=\u001b[39m CHARACTERS_MAPS[cfg\u001b[38;5;241m.\u001b[39mENV\u001b[38;5;241m.\u001b[39mSEQUENCE_TYPE]\n\u001b[0;32m---> 55\u001b[0m seq_arrays \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchars_dict[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m s]) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sequences])\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_arrays \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mtensor(seq_arrays, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[20], line 55\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevolution_model \u001b[38;5;241m=\u001b[39m EvolutionModelTorch(cfg\u001b[38;5;241m.\u001b[39mENV\u001b[38;5;241m.\u001b[39mEVOLUTION_MODEL)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchars_dict \u001b[38;5;241m=\u001b[39m CHARACTERS_MAPS[cfg\u001b[38;5;241m.\u001b[39mENV\u001b[38;5;241m.\u001b[39mSEQUENCE_TYPE]\n\u001b[0;32m---> 55\u001b[0m seq_arrays \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchars_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m s]) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sequences])\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_arrays \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mtensor(seq_arrays, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyError\u001b[0m: '-'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from itertools import combinations\n",
    "import math\n",
    "\n",
    "# --- PART 1: REWARD CALCULATION (UNCHANGED, BUT WITH DEBUGGING ADDED) ---\n",
    "\n",
    "# --- PART 1: REWARD CALCULATION (CORRECTED) ---\n",
    "\n",
    "# ... (MockCfgNode and CHARACTERS_MAPS are the same) ...\n",
    "\n",
    "class EvolutionModelTorch(nn.Module):\n",
    "    \"\"\"\n",
    "    This class now uses register_buffer to ensure its tensors (Q matrix, pi)\n",
    "    are moved to the correct device when .to(device) is called.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='JC69'):\n",
    "        super().__init__()\n",
    "        # Use register_buffer to make these part of the module's state\n",
    "        q_matrix = torch.tensor([[-3,1,1,1],[1,-3,1,1],[1,1,-3,1],[1,1,1,-3]], dtype=torch.float32) / 4.0\n",
    "        pi_vector = torch.tensor([0.25, 0.25, 0.25, 0.25], dtype=torch.float32)\n",
    "        self.register_buffer('Q', q_matrix)\n",
    "        self.register_buffer('pi', pi_vector)\n",
    "\n",
    "    def get_transition_matrix(self, t):\n",
    "        # self.Q is now on the correct device\n",
    "        return torch.matrix_exp(self.Q * t.item())\n",
    "        \n",
    "    def compute_partial_prob(self, data, at_root):\n",
    "        # The matmul will now work as both tensors are on the same device\n",
    "        child_probs = [torch.matmul(p.squeeze(0), self.get_transition_matrix(bl).T) for p, bl in data]\n",
    "        merged_likelihoods = child_probs[0]\n",
    "        for i in range(1, len(child_probs)):\n",
    "            merged_likelihoods *= child_probs[i]\n",
    "        merged_likelihoods = merged_likelihoods.unsqueeze(0)\n",
    "        \n",
    "        if at_root:\n",
    "            likelihood_per_site = torch.sum(self.pi * merged_likelihoods.squeeze(0), dim=1)\n",
    "            log_score = torch.sum(torch.log(likelihood_per_site + 1e-40))\n",
    "            return merged_likelihoods, log_score\n",
    "            \n",
    "        return merged_likelihoods, None\n",
    "\n",
    "class PhylogenticTreeEnv(nn.Module):\n",
    "    def __init__(self, cfg, sequences, device):\n",
    "        super(PhylogenticTreeEnv, self).__init__()\n",
    "        self.device = device # Store the device\n",
    "        # This will now correctly move the Q matrix and pi to the specified device\n",
    "        self.evolution_model = EvolutionModelTorch(cfg.ENV.EVOLUTION_MODEL).to(device)\n",
    "        self.chars_dict = CHARACTERS_MAPS[cfg.ENV.SEQUENCE_TYPE]\n",
    "        seq_arrays = np.array([np.array([self.chars_dict[c] for c in s]) for s in sequences])\n",
    "        self.seq_arrays = torch.nn.Parameter(torch.tensor(seq_arrays, dtype=torch.float32), requires_grad=False).to(device)\n",
    "\n",
    "    def compute_tree_log_score(self, ete_tree):\n",
    "        from ete3 import TreeNode\n",
    "        feature_dict = {}\n",
    "        internal_node_counter = self.seq_arrays.shape[0]\n",
    "        for node in ete_tree.traverse(\"preorder\"):\n",
    "            if not node.is_leaf() and not node.name:\n",
    "                node.name = str(internal_node_counter)\n",
    "                internal_node_counter += 1\n",
    "        \n",
    "        for node in ete_tree.traverse(\"postorder\"):\n",
    "            node_id = int(node.name)\n",
    "            if node.is_leaf():\n",
    "                feature_dict[node_id] = self.seq_arrays[node_id].unsqueeze(0)\n",
    "            else:\n",
    "                # **FIX APPLIED HERE**: Create the branch length tensor on the correct device.\n",
    "                child_data = [[feature_dict[int(c.name)], torch.tensor([c.dist], device=self.device)] for c in node.children]\n",
    "                feature, log_score = self.evolution_model.compute_partial_prob(child_data, node.is_root())\n",
    "                feature_dict[node_id] = feature\n",
    "                if node.is_root():\n",
    "                    return log_score\n",
    "        return torch.tensor(float('-inf'))\n",
    "\n",
    "def get_reward(newick_string, sequences, env):\n",
    "    \"\"\"Calculates the log-likelihood reward, now with error printing.\"\"\"\n",
    "    from ete3 import TreeNode\n",
    "    if not newick_string or not newick_string.endswith(';'):\n",
    "        return -math.inf, \"Invalid Newick format\"\n",
    "    try:\n",
    "        tree = TreeNode(newick_string)\n",
    "        leaf_names_in_tree = set(tree.get_leaf_names())\n",
    "        expected_leaf_names = set(str(i) for i in range(len(sequences)))\n",
    "        if leaf_names_in_tree != expected_leaf_names:\n",
    "            return -math.inf, f\"Tree missing leaves. Expected {expected_leaf_names}, got {leaf_names_in_tree}\"\n",
    "        \n",
    "        ll = env.compute_tree_log_score(tree)\n",
    "        \n",
    "        # Check for non-finite rewards\n",
    "        if not math.isfinite(ll.item()):\n",
    "             return -math.inf, \"Log-likelihood is not finite\"\n",
    "\n",
    "        return ll.item(), \"OK\"\n",
    "    except Exception as e:\n",
    "        # **ADDED**: Print the specific error for easier debugging.\n",
    "        print(f\"[Debug] Reward Error: {e} for tree: {newick_string}\") \n",
    "        return -math.inf, f\"Reward Error: {e}\"\n",
    "\n",
    "# ... (The TreeBuilder class and get_dna_embeddings function are the same) ...\n",
    "\n",
    "\n",
    "# --- PART 3: TRAINING & INFERENCE SCRIPT (WITH CORRECTIONS) ---\n",
    "\n",
    "def run_training(DNA_SEQUENCES=None):\n",
    "    # --- Setup ---\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if DNA_SEQUENCES is None:\n",
    "        DNA_SEQUENCES = [\"AGAACT\", \"AGATGT\", \"CGAACT\", \"CGATGT\"]\n",
    "    n_leaves = len(DNA_SEQUENCES)\n",
    "    \n",
    "    # Hyperparameters\n",
    "    epochs = 5000\n",
    "    learning_rate = 1e-4\n",
    "    # **MODIFIED**: Initialize baseline as None. We'll set it to the first valid reward.\n",
    "    reward_baseline = None \n",
    "\n",
    "    # --- Pre-compute embeddings ---\n",
    "    print(\"Pre-computing DNABERT embeddings...\")\n",
    "    dnabert_model = AutoModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True).to(device)\n",
    "    dnabert_model.eval()\n",
    "    dnabert_tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
    "    leaf_embeddings = get_dna_embeddings(DNA_SEQUENCES, dnabert_model, dnabert_tokenizer, device)\n",
    "    embedding_dim = leaf_embeddings.shape[1]\n",
    "    \n",
    "    # --- Initialize models and optimizer ---\n",
    "    agent = TreeBuilder(embedding_dim).to(device)\n",
    "    optimizer = optim.Adam(agent.parameters(), lr=learning_rate)\n",
    "    cfg = MockCfgNode({\n",
    "        'ENV': {\n",
    "            'REWARD': {'C': 0, 'SCALE': 1.0},\n",
    "            'SEQUENCE_TYPE': 'DNA',\n",
    "            'EVOLUTION_MODEL': 'JC69'\n",
    "        }\n",
    "    })\n",
    "    reward_env = PhylogenticTreeEnv(cfg, DNA_SEQUENCES, device)\n",
    "    \n",
    "    print(\"--- Starting Reinforcement Learning Training ---\\n\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        agent.train() # Set agent to training mode\n",
    "        active_nodes = {i: str(i) for i in range(n_leaves)}\n",
    "        active_embeddings = leaf_embeddings.clone()\n",
    "        all_log_probs = []\n",
    "\n",
    "        for _ in range(n_leaves - 1):\n",
    "            pair_logits, pair_indices = agent(active_embeddings)\n",
    "            action_distribution = Categorical(logits=pair_logits)\n",
    "            chosen_pair_idx = action_distribution.sample()\n",
    "            all_log_probs.append(action_distribution.log_prob(chosen_pair_idx))\n",
    "            \n",
    "            idx1_in_active, idx2_in_active = pair_indices[chosen_pair_idx]\n",
    "            \n",
    "            emb1 = active_embeddings[idx1_in_active].unsqueeze(0)\n",
    "            emb2 = active_embeddings[idx2_in_active].unsqueeze(0)\n",
    "            \n",
    "            # The branch predictor is now used inside the training loop to apply scaling\n",
    "            branch_lengths_raw = agent.branch_predictor(torch.cat((emb1, emb2), dim=1)).squeeze()\n",
    "            \n",
    "            # **FIX APPLIED HERE**: Rescale and add a minimum value (epsilon)\n",
    "            # This prevents branch lengths from being too close to zero.\n",
    "            bl1 = branch_lengths_raw[0].item() * 0.5 + 0.01 \n",
    "            bl2 = branch_lengths_raw[1].item() * 0.5 + 0.01\n",
    "\n",
    "            parent_embedding = agent.parent_embedding_creator(torch.cat((emb1, emb2), dim=1))\n",
    "\n",
    "            node1_newick = active_nodes.pop(list(active_nodes.keys())[idx1_in_active])\n",
    "            node2_newick = active_nodes.pop(list(active_nodes.keys())[idx2_in_active-1 if idx2_in_active > idx1_in_active else idx2_in_active])\n",
    "            \n",
    "            new_node_newick = f\"({node1_newick}:{bl1:.4f},{node2_newick}:{bl2:.4f})\"\n",
    "            new_node_id = max(active_nodes.keys()) + 1 if active_nodes else 0\n",
    "            active_nodes[new_node_id] = new_node_newick\n",
    "            \n",
    "            remaining_indices = sorted([i for i in range(len(active_embeddings)) if i not in (idx1_in_active, idx2_in_active)])\n",
    "            active_embeddings = torch.cat((active_embeddings[remaining_indices], parent_embedding), dim=0)\n",
    "\n",
    "        final_newick = list(active_nodes.values())[0] + \";\"\n",
    "        reward, status = get_reward(final_newick, DNA_SEQUENCES, reward_env)\n",
    "\n",
    "        if status == \"OK\":\n",
    "            # **MODIFIED**: Smart baseline initialization\n",
    "            if reward_baseline is None:\n",
    "                reward_baseline = reward\n",
    "            \n",
    "            policy_loss = -torch.sum(torch.stack(all_log_probs)) * (reward - reward_baseline)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            policy_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            reward_baseline = 0.95 * reward_baseline + 0.05 * reward\n",
    "        \n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Reward: {reward:.4f}, Baseline: {reward_baseline or -1:.4f}\")\n",
    "\n",
    "    # ... (Inference part remains the same, but also needs the branch length fix) ...\n",
    "    print(\"\\n--- Training Finished. Generating final tree greedily ---\")\n",
    "    agent.eval()\n",
    "    active_nodes = {i: str(i) for i in range(n_leaves)}\n",
    "    active_embeddings = leaf_embeddings.clone()\n",
    "    for _ in range(n_leaves - 1):\n",
    "        with torch.no_grad():\n",
    "            pair_logits, pair_indices = agent(active_embeddings)\n",
    "            chosen_pair_idx = torch.argmax(pair_logits)\n",
    "            idx1_in_active, idx2_in_active = pair_indices[chosen_pair_idx]\n",
    "            \n",
    "            emb1 = active_embeddings[idx1_in_active].unsqueeze(0)\n",
    "            emb2 = active_embeddings[idx2_in_active].unsqueeze(0)\n",
    "            branch_lengths_raw = agent.branch_predictor(torch.cat((emb1, emb2), dim=1)).squeeze()\n",
    "            \n",
    "            # **FIX APPLIED HERE TOO**\n",
    "            bl1 = branch_lengths_raw[0].item() * 0.5 + 0.01\n",
    "            bl2 = branch_lengths_raw[1].item() * 0.5 + 0.01\n",
    "\n",
    "            parent_embedding = agent.parent_embedding_creator(torch.cat((emb1, emb2), dim=1))\n",
    "        \n",
    "        node1_newick = active_nodes.pop(list(active_nodes.keys())[idx1_in_active])\n",
    "        node2_newick = active_nodes.pop(list(active_nodes.keys())[idx2_in_active-1 if idx2_in_active > idx1_in_active else idx2_in_active])\n",
    "        new_node_newick = f\"({node1_newick}:{bl1:.4f},{node2_newick}:{bl2:.4f})\"\n",
    "        new_node_id = max(active_nodes.keys()) + 1 if active_nodes else 0\n",
    "        active_nodes[new_node_id] = new_node_newick\n",
    "        \n",
    "        remaining_indices = sorted([i for i in range(len(active_embeddings)) if i not in (idx1_in_active, idx2_in_active)])\n",
    "        active_embeddings = torch.cat((active_embeddings[remaining_indices], parent_embedding), dim=0)\n",
    "    \n",
    "    final_newick = list(active_nodes.values())[0] + \";\"\n",
    "    final_reward, _ = get_reward(final_newick, DNA_SEQUENCES, reward_env)\n",
    "    print(f\"Final Greedy Tree: {final_newick}\")\n",
    "    print(f\"Final Log-Likelihood: {final_reward:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dnaseq = [dnadata[x] for x in dnakeys]\n",
    "    print(\"--- Running the complete training and inference pipeline ---\")\n",
    "    print(\"length of DNA sequences:\", len(dnaseq))\n",
    "    print(\"Running training with DNA sequences:\", dnaseq)\n",
    "    run_training(DNA_SEQUENCES= dnaseq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goedel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
